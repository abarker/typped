
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>typped.lexer &#8212; Typped  documentation</title>
    <link rel="stylesheet" href="../../_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/sidebar.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">Typped  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for typped.lexer</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="sd">A `Lexer` class instance is a general lexer/scanner/tokenizer.  It was designed</span>
<span class="sd">to be used by the `PrattParser` class, but it can also be used for other</span>
<span class="sd">lexical scanning applications.</span>

<span class="sd">The general purpose of the `Lexer` is to take a string of text and produce a</span>
<span class="sd">corresponding sequence of tokens from the text.  The set of possible tokens is</span>
<span class="sd">defined by the user, with a string label and a regex pattern that is searched</span>
<span class="sd">for in the program text.  Once initialized with text a `Lexer` instance is a</span>
<span class="sd">generator which sequentially produces tokens with its `next` method.  It is</span>
<span class="sd">also an iterator, so it can be used in loops, etc.</span>

<span class="sd">With some lexers the order in which tokens are defined is significant.  They</span>
<span class="sd">match regexes from a list of regexes, taking the first match without regard</span>
<span class="sd">to the length of the match.  The</span>
<span class="sd">`Lexer` class was designed to function independently of the order in which</span>
<span class="sd">tokens are defined.  The longest match is always returned, with ties broken</span>
<span class="sd">by an explicit priority mechanism.  This allows token definitions to be</span>
<span class="sd">organized in various ways.   They can all be done in one</span>
<span class="sd">place or spread around in the code in any order, however the programmer wants</span>
<span class="sd">to do it.</span>

<span class="sd">Defining tokens</span>
<span class="sd">===============</span>

<span class="sd">This section describes the low-level definition of tokens when using `Lexer` as</span>
<span class="sd">a standalone application.  To use tokens with a `PrattParser` instance, though,</span>
<span class="sd">you need to use the corresponding `def_token` method of the `PrattParser`</span>
<span class="sd">class.  That class adds extra attributes, methods, etc., to the tokens.  The</span>
<span class="sd">interface is generally the same.</span>

<span class="sd">A token for a left parenthesis would be defined like this::</span>

<span class="sd">    lex = typped.Lexer()</span>
<span class="sd">    lex.def_token(&quot;k_lpar&quot;, r&quot;lpar&quot;)</span>

<span class="sd">The string `k_lpar` is a label for the token.  The use of the string prefix</span>
<span class="sd">&quot;`k_`&quot; is a naming convention for token labels.  An identifier token could be</span>
<span class="sd">defined like this::</span>

<span class="sd">    lex.def_token(&quot;k_identifier&quot;, r&quot;[a-zA-Z_](?:\w*)&quot;, on_ties=-1)</span>

<span class="sd">Notice that in the definition of the identifier the keyword argument `on_ties`</span>
<span class="sd">is set to -1.  The lexer will by default always choose the longest string which</span>
<span class="sd">matches a defined regex pattern for a token.  If there is a tie then, by</span>
<span class="sd">default, an exception will be raised.  The `on_ties` value is used to break</span>
<span class="sd">ties; strings of the same length are sorted by that value and the</span>
<span class="sd">highest-priority string is chosen.  The default `on_ties` value is `0`.  Suppose</span>
<span class="sd">you also wanted a token for the string `mod`, and defined it as::</span>

<span class="sd">    lex.def_token(&quot;k_mod&quot;, r&quot;mod&quot;)</span>

<span class="sd">Since this token has a higher `on_ties` value, it will always take precedence over</span>
<span class="sd">the identifier token, even though both match and have the same length.</span>

<span class="sd">Begin and end tokens</span>
<span class="sd">====================</span>

<span class="sd">The lexer uses sentinel begin-token and end-token tokens for the beginning and</span>
<span class="sd">the end of the token sequence for text.  These tokens must be explicitly</span>
<span class="sd">defined (i.e., given string labels) either by calling `def_begin_end_tokens`::</span>

<span class="sd">    lex.def_begin_end_tokens(&quot;k_begin&quot;, &quot;k_end&quot;)</span>

<span class="sd">or else by setting the `default_begin_end_tokens` flag to `True` when</span>
<span class="sd">initializing the lexer::</span>

<span class="sd">    lex = Lexer(def_begin_end_tokens=True)</span>

<span class="sd">The default tokens have the labels `k_begin` and `k_end`.</span>

<span class="sd">The begin-token is never explicitly returned.  After the call to `set_text` to</span>
<span class="sd">define the text to tokenize and before any calls to `next` the begin-token is</span>
<span class="sd">the current token `lexer.token`.  So `lex.token` and `lex.peek(0)` would both</span>
<span class="sd">return the begin token.</span>

<span class="sd">After the end of the text the `next` method explicitly returns one end-token.</span>
<span class="sd">Calling `next` again raises `StopIteration` and halts the lexing of the</span>
<span class="sd">currently-set text.  All peeks beyond the end of the text are reported as</span>
<span class="sd">end-tokens.</span>

<span class="sd">Using the lexer</span>
<span class="sd">===============</span>

<span class="sd">This is a simple example of using the lexer.  Notice that multiple token definitions</span>
<span class="sd">can be combined using the `def_multi_tokens` method.  It is usually better to</span>
<span class="sd">define a shorter alias for the function call, however.::</span>

<span class="sd">    lex = Lexer()</span>

<span class="sd">    lex.def_begin_end_tokens(&quot;k_begin&quot;, &quot;k_end&quot;)</span>
<span class="sd">    lex.def_token(&quot;k_space&quot;, r&quot;[ \\t]+&quot;, ignore=True) # note + NOT *</span>
<span class="sd">    lex.def_token(&quot;k_newline&quot;, r&quot;[\\n\\f\\r\\v]+&quot;, ignore=True) # note + NOT *</span>
<span class="sd">    tokens = [</span>
<span class="sd">        (&quot;k_identifier&quot;, r&quot;[a-zA-Z_](?:\w*)&quot;)</span>
<span class="sd">        (&quot;k_plus&quot;, r&quot;\+&quot;)</span>
<span class="sd">        ]</span>
<span class="sd">    lex.def_multi_tokens(tokens)</span>

<span class="sd">    lex.set_text(&quot;x  + y&quot;)</span>

<span class="sd">    for t in lex:</span>
<span class="sd">        print(t)</span>

<span class="sd">The result is as follows:</span>
<span class="sd">::</span>

<span class="sd">    &lt;k_identifier,x&gt;</span>
<span class="sd">    &lt;k_plus,+&gt;</span>
<span class="sd">    &lt;k_identifier,y&gt;</span>
<span class="sd">    &lt;k_end,None&gt;</span>

<span class="sd">Notice that the end-token is actually returned, but the begin-token is not.</span>
<span class="sd">The method `def_default_whitespace` could alternately be used to define the</span>
<span class="sd">whitespace tokens.</span>

<span class="sd">User-accessible methods and attributes of `Lexer`</span>
<span class="sd">=================================================</span>

<span class="sd">The lexer class has many utility methods and user-accessible attributes.  Some</span>
<span class="sd">of the main ones are listed here.  One of the most commonly-accessed attributes</span>
<span class="sd">of a lexer `lex` is the current token, `lex.token`.</span>

<span class="sd">General methods:</span>

<span class="sd">* `next` --- return the next token</span>
<span class="sd">* `peek` --- peek at the next token without consuming it</span>
<span class="sd">* `go_back` --- go back in the text stream by some number of tokens</span>

<span class="sd">Helper methods:</span>

<span class="sd">* `match_next` --- matches the specified token, with various options</span>
<span class="sd">* `in_ignored_tokens` --- test if some particular token was ignored before the current one</span>
<span class="sd">* `no_ignored_after` --- true if no ignored tokens immediately follow current token</span>
<span class="sd">* `no_ignored_before` --- true if no ignored tokens immediately preceed current token</span>

<span class="sd">Some boolean-valued informational methods:</span>

<span class="sd">* `curr_token_is_first` --- true if the current token is the first returned</span>
<span class="sd">* `text_is_set` --- true only when text is currently set for scanning</span>

<span class="sd">Other attributes:</span>

<span class="sd">* `token` --- the current token (the most recent one returned by `next`)</span>
<span class="sd">* `all_token_count` --- num of tokens since text was set (begin and end not counted)</span>
<span class="sd">* `non_ignored_token_count` --- num of not-ignored tokens since text was set</span>
<span class="sd">* `default_helper_exception` --- the default exception for helpers like `match_next`</span>
<span class="sd">* `text_is_set` --- whether or not text has been set for the lexer</span>

<span class="sd">TODO, list more, and why not make some of these methods of `TokenNode` instead?</span>

<span class="sd">User-accessible attributes of tokens</span>
<span class="sd">====================================</span>

<span class="sd">The tokens returned by the lexer are instances of a subclass of the class</span>
<span class="sd">`TokenNode` (named that since the parser combines them into the nodes of a</span>
<span class="sd">parse tree).  The subclasses themselves represent the general kind of token,</span>
<span class="sd">for example if `k_identifier` was defined as a token label then a particular</span>
<span class="sd">subclass of `TokenNode` would be created to represent identifiers in general.</span>
<span class="sd">The particular instances of identifiers, found in the lexed text with their</span>
<span class="sd">actual string values, are represented by instances of the general class for</span>
<span class="sd">identifiers.</span>

<span class="sd">User-accessible methods of tokens.</span>

<span class="sd">* `is_begin_token` --- true when tokens is a begin token</span>
<span class="sd">* `is_end_token` --- true when tokens is a end token</span>
<span class="sd">* `is_begin_or_end_token` --- true when tokens is a begin_or_end_token</span>
<span class="sd">* `ignored_before_labels` --- just the token labels of the tokens ignored before</span>

<span class="sd">For a token named `t`, these attributes are available:</span>

<span class="sd">* `t.token_label` --- the string label of the token (which was defined with it)</span>
<span class="sd">* `t.value` --- the string value for the token, found in the lexed text</span>
<span class="sd">* `t.is_first` --- true iff this is the first non-begin token in the text</span>
<span class="sd">* `t.is_first_on_line` --- true iff this is the first token returned for a line</span>
<span class="sd">* `t.parent` --- can be set to the parent in a tree; set by the lexer to `None`</span>
<span class="sd">* `t.children` --- can be set to a list of children; set by the lexer to `[]`</span>
<span class="sd">* `t.original_matched_string` --- the original text that was consumed for this token</span>
<span class="sd">* `t.line_and_char` --- tuple of line number and character where the token started</span>
<span class="sd">* `t.char_index_in_program` --- the index of this token into the text set via `set_text`</span>
<span class="sd">* `t.ignored_before` --- a tuple of all tokens ignored immediately before this one</span>

<span class="sd">TODO, list other methods, too.</span>

<span class="sd">Initialization options</span>
<span class="sd">======================</span>

<span class="sd">There are several options that can be set on initialization, including the</span>
<span class="sd">level of token lookahead that is supported.</span>

<span class="sd">TODO</span>

<span class="sd">Code</span>
<span class="sd">====</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># TODO: implement move_back, the equivalent of push_back except you think of it</span>
<span class="c1"># as moving in the token buffer rather than pushing back a token (it is still a</span>
<span class="c1"># peek token).</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span><span class="p">,</span> <span class="n">absolute_import</span>

<span class="c1"># Run tests when invoked as a script.</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">pytest_helper</span>
    <span class="n">pytest_helper</span><span class="o">.</span><span class="n">script_run</span><span class="p">([</span><span class="s2">&quot;../../test/test_pratt_parser.py&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;../../test/test_matcher.py&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;../../test/test_lexer.py&quot;</span><span class="p">,</span>
                              <span class="p">],</span>
                              <span class="n">pytest_args</span><span class="o">=</span><span class="s2">&quot;-v&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">from</span> <span class="nn">.shared_settings_and_exceptions</span> <span class="k">import</span> <span class="n">LexerException</span><span class="p">,</span> <span class="n">is_subclass_of</span>
<span class="kn">from</span> <span class="nn">.matcher</span> <span class="k">import</span> <span class="n">Matcher</span>

<span class="c1">#</span>
<span class="c1"># TokenNode</span>
<span class="c1">#</span>

<div class="viewcode-block" id="TokenNode"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenNode">[docs]</a><span class="k">class</span> <span class="nc">TokenNode</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The base class for token objects.  Each different kind of token is represented</span>
<span class="sd">    by a subclass of this class.  Instances of the tokens in the program text are</span>
<span class="sd">    represented by instances of the subclass for that kind of token.</span>

<span class="sd">    The attribute `token_label` is the string token label for the kind of token</span>
<span class="sd">    represented by an instance.  The attribute `value` is set to the actual</span>
<span class="sd">    string value in the lexed text which matched the regex of the token.  The</span>
<span class="sd">    attribute `ignored_before` is a tuple of all tokens ignored just</span>
<span class="sd">    before the lexer got this token.</span>

<span class="sd">    The attribute `children` is a list of the child nodes, and `parent` is the</span>
<span class="sd">    parent.  Indexing a `TokenNode` class also returns the corresponding child</span>
<span class="sd">    node, i.e. `t_node[0]` would be the leftmost child.&quot;&quot;&quot;</span>

    <span class="n">token_label</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># A label for subclasses representing kinds of tokens.</span>
    <span class="n">original_matched_string</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="c1"># Default, for begin- and end-tokens.</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the TokenNode.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignored_before</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># Values ignored by lexer just before.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># The actual parsed text string for the token.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">children</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># Args to functions are their children in parse tree.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># The parent in a tree of nodes.</span>

<div class="viewcode-block" id="TokenNode.original_text"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenNode.original_text">[docs]</a>    <span class="k">def</span> <span class="nf">original_text</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the original text that was read in lexing the token, including</span>
<span class="sd">        any ignored text.&quot;&quot;&quot;</span>
        <span class="c1">#ignored_strings = [ s.value for s in self.ignored_before ]</span>
        <span class="c1">#joined = &quot;&quot;.join(ignored_strings) + self.value</span>
        <span class="c1">#assert joined == self.original_matched_string # A debugging test.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_matched_string</span></div>

<div class="viewcode-block" id="TokenNode.ignored_before_labels"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenNode.ignored_before_labels">[docs]</a>    <span class="k">def</span> <span class="nf">ignored_before_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the list of token labels of tokens which were ignored just</span>
<span class="sd">        before this token.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">token_label</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignored_before</span><span class="p">]</span></div>

<div class="viewcode-block" id="TokenNode.append_children"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenNode.append_children">[docs]</a>    <span class="k">def</span> <span class="nf">append_children</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">token_nodes</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Append all the arguments as children, also setting their parent to self.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">token_nodes</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
            <span class="n">t</span><span class="o">.</span><span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span></div>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Use indexing to access the children.  No check is made, however, to see</span>
<span class="sd">        if the correct number of children exist.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

<div class="viewcode-block" id="TokenNode.convert_to_AST"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenNode.convert_to_AST">[docs]</a>    <span class="k">def</span> <span class="nf">convert_to_AST</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">convert_TokenNode_to_AST_node_fun</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call this on the root node.  Converts the token tree to an abstract</span>
<span class="sd">        syntax tree.  This basically converts the nodes one-to-one to a more</span>
<span class="sd">        convenient type of node for the AST of a given application.  The</span>
<span class="sd">        function `convert_TokenNode_to_AST_node_fun` should take one argument,</span>
<span class="sd">        a `TokenNode` instance, and return an AST node instance for the</span>
<span class="sd">        corresponding AST node.  The only requirement for the AST nodes is that</span>
<span class="sd">        they have a method called `append_children`.  The `ast_data` attribute</span>
<span class="sd">        of a node can be used to save information useful in the transformation.&quot;&quot;&quot;</span>
        <span class="n">ast_node</span> <span class="o">=</span> <span class="n">convert_TokenNode_to_AST_node_fun</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="n">ast_node</span><span class="o">.</span><span class="n">append_children</span><span class="p">(</span>
                    <span class="n">child</span><span class="o">.</span><span class="n">convert_to_AST</span><span class="p">(</span><span class="n">convert_TokenNode_to_AST_node_fun</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ast_node</span></div>

    <span class="c1">#</span>
    <span class="c1"># Informational methods.</span>
    <span class="c1">#</span>

<div class="viewcode-block" id="TokenNode.is_begin_token"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenNode.is_begin_token">[docs]</a>    <span class="k">def</span> <span class="nf">is_begin_token</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Test whether this token is the begin-token.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_label</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_table</span><span class="o">.</span><span class="n">begin_token_label</span></div>

<div class="viewcode-block" id="TokenNode.is_end_token"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenNode.is_end_token">[docs]</a>    <span class="k">def</span> <span class="nf">is_end_token</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Test whether this token is the end-token.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_label</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_table</span><span class="o">.</span><span class="n">end_token_label</span></div>

<div class="viewcode-block" id="TokenNode.is_begin_or_end_token"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenNode.is_begin_or_end_token">[docs]</a>    <span class="k">def</span> <span class="nf">is_begin_or_end_token</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Test whether this token is either the begin- or end-token.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_begin_token</span><span class="p">()</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_end_token</span><span class="p">()</span></div>

    <span class="c1">#</span>
    <span class="c1"># Various representations.  Note a token can be considered a node or a subtree.</span>
    <span class="c1"># Coming straight from the Lexer, though, they do not yet have any children.</span>
    <span class="c1">#</span>

<div class="viewcode-block" id="TokenNode.traditional_repr"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenNode.traditional_repr">[docs]</a>    <span class="k">def</span> <span class="nf">traditional_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Representation as a string that looks like class initialization.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;TokenNode()&quot;</span></div>

<div class="viewcode-block" id="TokenNode.value_repr"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenNode.value_repr">[docs]</a>    <span class="k">def</span> <span class="nf">value_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Token representation as its value.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">)</span></div>

<div class="viewcode-block" id="TokenNode.label_repr"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenNode.label_repr">[docs]</a>    <span class="k">def</span> <span class="nf">label_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Token representation as its token label.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_label</span><span class="p">)</span></div>

<div class="viewcode-block" id="TokenNode.summary_repr"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenNode.summary_repr">[docs]</a>    <span class="k">def</span> <span class="nf">summary_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Token representation as a summarizing string containing both the label and</span>
<span class="sd">        the value.&quot;&quot;&quot;</span>
        <span class="n">value_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">value_str</span> <span class="o">=</span> <span class="s2">&quot;&#39;&quot;</span> <span class="o">+</span> <span class="n">value_str</span> <span class="o">+</span> <span class="s2">&quot;&#39;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">{0}</span><span class="s2">,</span><span class="si">{1}</span><span class="s2">&gt;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_label</span><span class="p">,</span> <span class="n">value_str</span><span class="p">)</span></div>

<div class="viewcode-block" id="TokenNode.tree_repr"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenNode.tree_repr">[docs]</a>    <span class="k">def</span> <span class="nf">tree_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Token representation as the root of a parse subtree, with formatting.</span>
<span class="sd">        The optional `indent` parameter can be either an indent string or else</span>
<span class="sd">        an integer for the number of spaces to indent.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">num_indent</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">indent</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">indent</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="n">num_indent</span>
        <span class="n">string</span> <span class="o">=</span> <span class="n">indent</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_repr</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="n">string</span> <span class="o">+=</span> <span class="n">c</span><span class="o">.</span><span class="n">tree_repr</span><span class="p">(</span><span class="n">indent</span><span class="o">=</span><span class="n">indent</span><span class="o">+</span><span class="s2">&quot; &quot;</span><span class="o">*</span><span class="mi">4</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">string</span></div>

<div class="viewcode-block" id="TokenNode.string_tree_repr"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenNode.string_tree_repr">[docs]</a>    <span class="k">def</span> <span class="nf">string_tree_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">only_vals</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">only_labels</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Token representation as the root of a parse subtree, in a string format.</span>
<span class="sd">        This is the default representation, used for `__repr__`.&quot;&quot;&quot;</span>
        <span class="n">string</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_repr</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">only_vals</span><span class="p">:</span> <span class="n">string</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_repr</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">only_labels</span><span class="p">:</span> <span class="n">string</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_repr</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="n">string</span> <span class="o">+=</span> <span class="s2">&quot;(&quot;</span>
            <span class="n">string</span> <span class="o">+=</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">string_tree_repr</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">)</span>
            <span class="n">string</span> <span class="o">+=</span> <span class="s2">&quot;)&quot;</span>
        <span class="k">return</span> <span class="n">string</span></div>

<div class="viewcode-block" id="TokenNode.old_repr"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenNode.old_repr">[docs]</a>    <span class="k">def</span> <span class="nf">old_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This old representation is kept *only* because it is used in some tests.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_label</span> <span class="o">==</span> <span class="s2">&quot;k_number&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;[literal </span><span class="si">{0}</span><span class="s2">]&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_label</span> <span class="o">==</span> <span class="s2">&quot;k_lpar&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
                <span class="k">return</span> <span class="s2">&quot;[k_lpar </span><span class="si">{0}</span><span class="s2"> k_rpar]&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">old_repr</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="s2">&quot;[literal k_lpar]&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">str_val</span> <span class="o">=</span> <span class="s2">&quot;[&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span> <span class="n">str_val</span> <span class="o">+=</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">a</span><span class="o">.</span><span class="n">old_repr</span><span class="p">()</span>
            <span class="n">str_val</span> <span class="o">+=</span> <span class="s2">&quot;]&quot;</span>
            <span class="k">return</span> <span class="n">str_val</span></div>
    <span class="fm">__repr__</span> <span class="o">=</span> <span class="n">string_tree_repr</span></div>


<div class="viewcode-block" id="basic_token_subclass_factory"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.basic_token_subclass_factory">[docs]</a><span class="k">def</span> <span class="nf">basic_token_subclass_factory</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Create and return a new token subclass representing tokens with label</span>
<span class="sd">    `token_label`.  This function is called from the `_create_token_subclass`</span>
<span class="sd">    method  of `TokenTable` when it needs to create a new one to</span>
<span class="sd">    start with.  This function **should not be called directly**, since</span>
<span class="sd">    additional attributes (such as the token label and a new subclass name)</span>
<span class="sd">    also need to be added to the generated subclass.</span>

<span class="sd">    This function is the default argument to the `token_subclassing_fun`</span>
<span class="sd">    keyword argument of the initializer for `TokenTable`.  Users</span>
<span class="sd">    can define their own such function in order to add methods to token objects</span>
<span class="sd">    which are particular to their own application (the `PrattParser` class does</span>
<span class="sd">    this, for example).</span>

<span class="sd">    Note that using a separate subclass for each token label allows for</span>
<span class="sd">    attributes and methods specific to a kind of token to be pasted onto the</span>
<span class="sd">    class itself without conflicts.  For example, the `PrattParser` subclass</span>
<span class="sd">    adds head handler and tail handler methods which are specific to a given</span>
<span class="sd">    token label.&quot;&quot;&quot;</span>
    <span class="c1"># If we instead used a metaclass to generate the token subclasses instead</span>
    <span class="c1"># of a factory then it would be possible to define a __repr__ that controls</span>
    <span class="c1"># how the token-representing classes themselves are printed (they are ugly</span>
    <span class="c1"># now).  How much would this complicate things for users who wanted to</span>
    <span class="c1"># create their own factory?  Kind of an advanced topic for many people.  If</span>
    <span class="c1"># they could simply declare a metaclass that would be OK, but might need</span>
    <span class="c1"># args passed, etc.  See version in PrattParser module.</span>
    <span class="k">class</span> <span class="nc">TokenSubclass</span><span class="p">(</span><span class="n">TokenNode</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This is the class returned by the factory function.&quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">TokenSubclass</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span> <span class="c1"># Call base class __init__.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">value</span> <span class="c1"># Passed in for instances by the Lexer token generator.</span>

    <span class="k">return</span> <span class="n">TokenSubclass</span></div>

<span class="c1">#</span>
<span class="c1"># Token table.</span>
<span class="c1">#</span>

<div class="viewcode-block" id="TokenTable"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenTable">[docs]</a><span class="k">class</span> <span class="nc">TokenTable</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A symbol table holding subclasses of the `TokenNode` class for each token label</span>
<span class="sd">    defined in a `Lexer` instance.  Also has methods for operating on tokens.</span>
<span class="sd">    Each `Lexer` instance contains an instance of this class to save the subclasses for</span>
<span class="sd">    the kinds of tokens which have been defined for it.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_subclass_factory_fun</span><span class="o">=</span><span class="n">basic_token_subclass_factory</span><span class="p">,</span>
                       <span class="n">pattern_matcher_instance</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the token table.</span>

<span class="sd">        The parameter `token_subclass_factory_fun` can be passed a function to</span>
<span class="sd">        be used to generate token subclasses, taking a token label as an</span>
<span class="sd">        argument.  The default is `basic_token_subclass_factory`.</span>

<span class="sd">        The parameter `pattern_matcher_instance` can be passed an empty pattern</span>
<span class="sd">        matcher instance, which will be used instead of the default one.  In</span>
<span class="sd">        this way users can define their own matchers, or pass in whatever options</span>
<span class="sd">        they choose to the initializer of the default one.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_subclassing_fun</span> <span class="o">=</span> <span class="n">token_subclass_factory_fun</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_subclass_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lex</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># The lexer currently associated with this token table.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">begin_token_label</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">begin_token_subclass</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_token_label</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_token_subclass</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">pattern_matcher_instance</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pattern_matcher_instance</span> <span class="o">=</span> <span class="n">Matcher</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pattern_matcher</span> <span class="o">=</span> <span class="n">pattern_matcher_instance</span>

    <span class="k">def</span> <span class="nf">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Test whether a token subclass for `token_label` has been stored.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">token_label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_subclass_dict</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Look up the subclasses of base class `TokenNode` corresponding to</span>
<span class="sd">        `token_label` in the token table and return it.  Raises a</span>
<span class="sd">        `LexerException` if no subclass is found for the token label.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">token_label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_subclass_dict</span><span class="p">:</span>
            <span class="n">TokenSubclass</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_subclass_dict</span><span class="p">[</span><span class="n">token_label</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s2">&quot;No token with label &#39;</span><span class="si">{0}</span><span class="s2">&#39; is in the token table.&quot;</span>
                                   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">token_label</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">TokenSubclass</span>

    <span class="k">def</span> <span class="nf">_create_token_subclass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">,</span> <span class="n">store_in_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a subclass for tokens with label `token_label` and store it</span>
<span class="sd">        in the token table.  Return the new subclass.  Raises a `LexerException`</span>
<span class="sd">        if a subclass for `token_label` has already been created.  If</span>
<span class="sd">        `store_in_dict` is `False` then the token is not stored.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">token_label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_subclass_dict</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s2">&quot;In `_create_token_subclass`, already created the&quot;</span>
                    <span class="s2">&quot; token subclass for token_label &#39;</span><span class="si">{0}</span><span class="s2">&#39;.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">token_label</span><span class="p">))</span>
        <span class="c1"># Create a new token subclass for token_label and add some attributes.</span>
        <span class="n">TokenSubclass</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_subclassing_fun</span><span class="p">()</span>
        <span class="n">TokenSubclass</span><span class="o">.</span><span class="n">token_label</span> <span class="o">=</span> <span class="n">token_label</span>
        <span class="n">TokenSubclass</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">=</span> <span class="s2">&quot;TokenClass_&quot;</span> <span class="o">+</span> <span class="n">token_label</span> <span class="c1"># For debugging.</span>
        <span class="c1"># Store the newly-created subclass in the token_dict.</span>
        <span class="k">if</span> <span class="n">store_in_dict</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">token_subclass_dict</span><span class="p">[</span><span class="n">token_label</span><span class="p">]</span> <span class="o">=</span> <span class="n">TokenSubclass</span>
        <span class="k">return</span> <span class="n">TokenSubclass</span>

<div class="viewcode-block" id="TokenTable.undef_token_subclass"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenTable.undef_token_subclass">[docs]</a>    <span class="k">def</span> <span class="nf">undef_token_subclass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Un-define the token with label token_label.  The `TokenNode` subclass</span>
<span class="sd">        previously associated with that label is removed from the dictionary.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_subclass_dict</span><span class="p">[</span><span class="n">token_label</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="k">return</span> <span class="c1"># Not saved in dict, ignore.</span></div>

<div class="viewcode-block" id="TokenTable.undef_token"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenTable.undef_token">[docs]</a>    <span class="k">def</span> <span class="nf">undef_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Undefine the token corresponding to `token_label`.&quot;&quot;&quot;</span>
        <span class="c1"># Remove from the list of defined tokens and from the token table.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">undef_token_subclass</span><span class="p">(</span><span class="n">token_label</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pattern_matcher</span><span class="o">.</span><span class="n">undef_pattern</span><span class="p">(</span><span class="n">token_label</span><span class="p">)</span></div>

<div class="viewcode-block" id="TokenTable.def_token"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenTable.def_token">[docs]</a>    <span class="k">def</span> <span class="nf">def_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">,</span> <span class="n">regex_string</span><span class="p">,</span> <span class="n">on_ties</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignore</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                  <span class="n">matcher_options</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Define a token and the regex to recognize it.  Returns the new</span>
<span class="sd">        token subclass.</span>

<span class="sd">        The label `token_label` is the label for the kind of token.</span>

<span class="sd">        The label `regex_string` is a Python regular expression defining the</span>
<span class="sd">        text strings which match for the token.  If `regex_string` is set to</span>
<span class="sd">        `None` then a dummy token will be created which is never searched for</span>
<span class="sd">        in the lexed text.  To better catch errors it does not have a default</span>
<span class="sd">        value, so setting it to `None` must be done explicitly.</span>

<span class="sd">        Setting `ignore=True` will cause all such tokens to be ignored (except</span>
<span class="sd">        that they will be placed on the `ignored_before` list of the</span>
<span class="sd">        non-ignored token that they precede).</span>

<span class="sd">        In case of ties for the longest match in scanning, the integer</span>
<span class="sd">        `on_ties` values are used to break the ties.  If any two are still</span>
<span class="sd">        equal an exception will be raised.</span>

<span class="sd">        The `option` parameter takes a string value, which is then passed to</span>
<span class="sd">        the `insert_pattern` method of whatever matcher is being used.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">token_label</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s2">&quot;A token with label &#39;</span><span class="si">{0}</span><span class="s2">&#39; is already defined.  It &quot;</span>
            <span class="s2">&quot;must be undefined before it can be redefined.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">token_label</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">regex_string</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pattern_matcher</span><span class="o">.</span><span class="n">insert_pattern</span><span class="p">(</span><span class="n">token_label</span><span class="p">,</span> <span class="n">regex_string</span><span class="p">,</span>
                         <span class="n">on_ties</span><span class="p">,</span> <span class="n">ignore</span><span class="o">=</span><span class="n">ignore</span><span class="p">,</span> <span class="n">matcher_options</span><span class="o">=</span><span class="n">matcher_options</span><span class="p">)</span>

        <span class="c1"># Initialize and return a bare-bones, default token_subclass.</span>
        <span class="n">tok</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_token_subclass</span><span class="p">(</span><span class="n">token_label</span><span class="p">)</span>
        <span class="n">tok</span><span class="o">.</span><span class="n">token_table</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="k">return</span> <span class="n">tok</span></div>

<div class="viewcode-block" id="TokenTable.def_begin_token"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenTable.def_begin_token">[docs]</a>    <span class="k">def</span> <span class="nf">def_begin_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">begin_token_label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Define the begin-token.  The lexer&#39;s `def_begin_end_tokens` method</span>
<span class="sd">        should usually be called instead.&quot;&quot;&quot;</span>
        <span class="n">tok</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">def_token</span><span class="p">(</span><span class="n">begin_token_label</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">begin_token_label</span> <span class="o">=</span> <span class="n">begin_token_label</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">begin_token_subclass</span> <span class="o">=</span> <span class="n">tok</span>
        <span class="k">return</span> <span class="n">tok</span></div>

<div class="viewcode-block" id="TokenTable.def_end_token"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenTable.def_end_token">[docs]</a>    <span class="k">def</span> <span class="nf">def_end_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">end_token_label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Define the end-token.  The `def_begin_end_tokens` method should usually</span>
<span class="sd">        be called instead.&quot;&quot;&quot;</span>
        <span class="n">tok</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">def_token</span><span class="p">(</span><span class="n">end_token_label</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_token_label</span> <span class="o">=</span> <span class="n">end_token_label</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_token_subclass</span> <span class="o">=</span> <span class="n">tok</span>
        <span class="k">return</span> <span class="n">tok</span></div>

<div class="viewcode-block" id="TokenTable.get_next_token_label_and_value"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenTable.get_next_token_label_and_value">[docs]</a>    <span class="k">def</span> <span class="nf">get_next_token_label_and_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">program</span><span class="p">,</span> <span class="n">prog_unprocessed_indices</span><span class="p">,</span>
                                             <span class="n">ERROR_MSG_TEXT_SNIPPET_SIZE</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the next token label for the start of the current program</span>
<span class="sd">        text, as in the string `program` and indexed by the numbers in</span>
<span class="sd">        the ordered-pair tuple `prog_unprocessed`.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pattern_matcher</span><span class="o">.</span><span class="n">get_next_token_label_and_value</span><span class="p">(</span>
                                              <span class="n">program</span><span class="p">,</span> <span class="n">prog_unprocessed_indices</span><span class="p">,</span>
                                              <span class="n">ERROR_MSG_TEXT_SNIPPET_SIZE</span><span class="p">)</span></div>

<div class="viewcode-block" id="TokenTable.ignored_tokens"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenTable.ignored_tokens">[docs]</a>    <span class="k">def</span> <span class="nf">ignored_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the set of ignored tokens.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pattern_matcher</span><span class="o">.</span><span class="n">ignore_tokens</span></div></div>

<span class="c1">#</span>
<span class="c1"># Lexer</span>
<span class="c1">#</span>

<div class="viewcode-block" id="TokenBuffer"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenBuffer">[docs]</a><span class="k">class</span> <span class="nc">TokenBuffer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;An abstraction of the token buffer.  This is used internally by the</span>
<span class="sd">    `Lexer` class and should not usually be accessed by users.  It is basically</span>
<span class="sd">    a nice wrapper over an underlying deque, but this is complicated by the</span>
<span class="sd">    need to save persistent state pointers into the buffer even in fixed-size</span>
<span class="sd">    buffers when tokens at the front get dropped.</span>

<span class="sd">    Previous tokens are stored in the same deque as the current token and any</span>
<span class="sd">    lookahead tokens.  The default indexing is relative to the current token,</span>
<span class="sd">    at `current_offset`, which is zero for the current token.  (The current</span>
<span class="sd">    offset is itself relative to a reference point, but users do not need to</span>
<span class="sd">    know that detail).&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_getter_fun</span><span class="p">,</span> <span class="n">max_peek</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_deque_size</span><span class="o">=-</span><span class="mi">1</span><span class="p">,):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the buffer.  If `max_deque_size` equals -1 then the</span>
<span class="sd">        size is unlimited (`None` is not used so that Cython has a single type).</span>
<span class="sd">        Similarly for `max_peek`, the maximum peek lookahead allowed.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_getter_fun</span> <span class="o">=</span> <span class="n">token_getter_fun</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_deque_size</span> <span class="o">=</span> <span class="n">max_deque_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_peek</span> <span class="o">=</span> <span class="n">max_peek</span>
        <span class="c1"># Any popleft operations are done explicitly, so maxlen=None.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Indices are relative to current_offset, and current_offset is</span>
        <span class="c1"># relative to reference_point.  This is because a fixed-size deque can</span>
        <span class="c1"># drop elements.  The current_offset is not relative to 0 because then</span>
        <span class="c1"># a saved offset would become invalid when items are popped off the</span>
        <span class="c1"># left of the deque.  The reference point is decremented for every</span>
        <span class="c1"># deque element popped off the left, and at no other time.  That way,</span>
        <span class="c1"># the current offset can be saved and remain valid until the</span>
        <span class="c1"># `TokenBuffer` is reset (though the referenced item may get deleted).</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reference_point</span> <span class="o">=</span> <span class="mi">0</span>

<div class="viewcode-block" id="TokenBuffer.reset"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenBuffer.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">begin_token</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the token buffer, or clear an reset it.  Any saved</span>
<span class="sd">        offsets are no longer valid, but no check is made for that.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reference_point</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_append</span><span class="p">(</span><span class="n">begin_token</span><span class="p">)</span></div>

<div class="viewcode-block" id="TokenBuffer.state_to_offset"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenBuffer.state_to_offset">[docs]</a>    <span class="k">def</span> <span class="nf">state_to_offset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the offset into the current deque that corresponds to what</span>
<span class="sd">        was the offset (absolute index to the current token) at the time when</span>
<span class="sd">        the state was saved.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">state</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_point</span></div>

<div class="viewcode-block" id="TokenBuffer.get_state"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenBuffer.get_state">[docs]</a>    <span class="k">def</span> <span class="nf">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a buffer state indicator that can be returned to later.  The</span>
<span class="sd">        `go_back` or `push_back` methods of the lexer use this.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offset_to_absolute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Index the buffer relative to the current offset.  Zero is the</span>
<span class="sd">        current token.  Negative indices go back in the buffer.  They **do not**</span>
<span class="sd">        index from the end of the buffer, as with ordinary Python indexing.&quot;&quot;&quot;</span>
        <span class="c1"># Slices are CURRENTLY NOT allowed.  What should they return?  How</span>
        <span class="c1"># do you know where the zero point is?</span>
        <span class="c1">#if isinstance(index, slice): # Handle slices recursively.</span>
        <span class="c1">#    start = index.start</span>
        <span class="c1">#    stop = index.stop</span>
        <span class="c1">#    step = index.step</span>
        <span class="c1">#    # The indices call returns the above three in a tuple.</span>
        <span class="c1">#    return [self[i] for i in range(*index.indices(len(self)))]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span> <span class="c1"># The ordinary case.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_peek</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">index</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_peek</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s2">&quot;User-set maximum peeking level of </span><span class="si">{0}</span><span class="s2"> was&quot;</span>
                                     <span class="s2">&quot; exceeded.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_peek</span><span class="p">))</span>
            <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">_index_to_absolute</span><span class="p">(</span><span class="n">index</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">is_end_token</span><span class="p">():</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_append</span><span class="p">()</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_index_to_absolute</span><span class="p">(</span><span class="n">index</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Invalid argument type in __getitem__ of TokenBuffer.&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="TokenBuffer.num_saved_previous_tokens"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenBuffer.num_saved_previous_tokens">[docs]</a>    <span class="k">def</span> <span class="nf">num_saved_previous_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the number of tokens before the current token that are saved.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offset_to_absolute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span><span class="p">)</span></div>

<div class="viewcode-block" id="TokenBuffer.num_tokens_after_current"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenBuffer.num_tokens_after_current">[docs]</a>    <span class="k">def</span> <span class="nf">num_tokens_after_current</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;An informational method.  Returns the number of tokens from</span>
<span class="sd">        the current token to the end of the token buffer.  Some may have been</span>
<span class="sd">        read past the position of the current token due to peeks or</span>
<span class="sd">        pushbacks.&quot;&quot;&quot;</span>
        <span class="n">begin_point</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offset_to_absolute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">)</span> <span class="o">-</span> <span class="n">begin_point</span></div>

<div class="viewcode-block" id="TokenBuffer.move_forward"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenBuffer.move_forward">[docs]</a>    <span class="k">def</span> <span class="nf">move_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_toks</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Move the current token (i.e., the offset) forward by one.  This is</span>
<span class="sd">        the token buffer&#39;s equivalent of `next`, except that it returns</span>
<span class="sd">        previously-buffered tokens if possible.  The `Lexer` method `next`</span>
<span class="sd">        should always be called by users of that class, because it also handles</span>
<span class="sd">        some other things.</span>

<span class="sd">        Attempts to move past the first end-token leave the current offset at</span>
<span class="sd">        the first end-token.  No new tokens are added to the buffer.  The</span>
<span class="sd">        end-token is returned.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_toks</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_end_token</span><span class="p">():</span>
                <span class="k">break</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fill_to_current_offset</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="TokenBuffer.move_back"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.TokenBuffer.move_back">[docs]</a>    <span class="k">def</span> <span class="nf">move_back</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_toks</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Move the current token (i.e., offset) back `num_toks` tokens.  Will</span>
<span class="sd">        always stop at the begin-token.  Users should check the condition if it</span>
<span class="sd">        matters.  If the move attempts to move back to before the</span>
<span class="sd">        currently-saved tokens, but the begin-token is no longer saved, then a</span>
<span class="sd">        `LexerException` is raised.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span> <span class="o">-=</span> <span class="n">num_toks</span>
        <span class="n">absolute_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offset_to_absolute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">absolute_index</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span> <span class="o">+=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">absolute_index</span><span class="p">)</span>
            <span class="n">curr_token</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">curr_token</span><span class="o">.</span><span class="n">is_begin_token</span><span class="p">():</span>
                <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s2">&quot;Not enough saved tokens to move back to the&quot;</span>
                                     <span class="s2">&quot; begin-token in the `move_back` method.&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">curr_token</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">curr_token</span></div>

    <span class="c1">#</span>
    <span class="c1"># Internal utility methods below.</span>
    <span class="c1">#</span>

    <span class="k">def</span> <span class="nf">_index_to_absolute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Convert an index into an absolute index into the current deque.</span>
<span class="sd">        Note that any changes to the current offset or to the reference</span>
<span class="sd">        point (the latter via _append) will invalidate the absolute reference.</span>
<span class="sd">        In those cases it will need to be re-calculated.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">index</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_point</span>

    <span class="k">def</span> <span class="nf">_offset_to_absolute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Convert an offset into an absolute index into the current deque.</span>
<span class="sd">        Note that calls to `_append` can modify the reference point and</span>
<span class="sd">        invalidate the absolute index.  Needs to be re-calculated after</span>
<span class="sd">        such a call.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">offset</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_point</span>

    <span class="k">def</span> <span class="nf">_fill_to_current_offset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;If the current offset points past the end of the token buffer then</span>
<span class="sd">        get tokens and append them until it is a valid index.  Note this</span>
<span class="sd">        calls `_append`.  If the current offset is past the first end token</span>
<span class="sd">        in the text then the current offset point is reset to the first end</span>
<span class="sd">        token.  Only one end token is ever stored in the buffer.&quot;&quot;&quot;</span>
        <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offset_to_absolute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_append</span><span class="p">()</span> <span class="c1"># Note this call can change self.reference_point.</span>

    <span class="k">def</span> <span class="nf">_pop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Users should not call.  Pop off the rightmost item and return it.  Moves</span>
<span class="sd">        the current token backward if necessary.&quot;&quot;&quot;</span>
        <span class="n">retval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offset_to_absolute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">retval</span>

    <span class="k">def</span> <span class="nf">_append</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tok</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Append to buffer and fix current index if necessary.  Users should not</span>
<span class="sd">        call.  If `tok` is not set then the token to append is obtained from the</span>
<span class="sd">        `token_getter_fun` function.</span>

<span class="sd">        Note that this is the **only** method that ever gets tokens directly</span>
<span class="sd">        from the token getter function.&quot;&quot;&quot;</span>
        <span class="c1"># TODO: should this fill with end tokens, or stop at the first end token?</span>
        <span class="k">if</span> <span class="n">tok</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tok</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_getter_fun</span><span class="p">()</span>
            <span class="c1"># TODO: below causes a FAIL with go_back hanging... probably __getitem__</span>
            <span class="c1"># calling but not compensating for this behavior...</span>
            <span class="k">if</span> <span class="n">tok</span><span class="o">.</span><span class="n">is_end_token</span><span class="p">()</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">is_end_token</span><span class="p">():</span>
                <span class="k">return</span> <span class="n">tok</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tok</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_deque_size</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
                <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_deque_size</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reference_point</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="o">.</span><span class="n">popleft</span><span class="p">()</span> <span class="c1"># Do an explicit popleft.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offset_to_absolute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s2">&quot;Error in TokenBuffer:&quot;</span>
                    <span class="s2">&quot; Maximum buffer size is too small for the amount of peeking.&quot;</span>
                    <span class="s2">&quot; Current token was deleted.&quot;</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_deque_size</span></div>


<div class="viewcode-block" id="GenTokenState"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.GenTokenState">[docs]</a><span class="k">class</span> <span class="nc">GenTokenState</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The state of the token_generator program execution.&quot;&quot;&quot;</span>
    <span class="n">ordinary</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">end</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">uninitialized</span> <span class="o">=</span> <span class="mi">3</span></div>

<span class="c1"># The beginnings of a state tuple for the Lexer.  NOT YET USED AT ALL, but it would</span>
<span class="c1"># be more elegant than the current ad hoc state restoration approach.</span>
<span class="n">LexerState</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span><span class="s2">&quot;LexerState&quot;</span><span class="p">,</span> <span class="p">[</span>
                           <span class="s2">&quot;x&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;y&quot;</span><span class="p">,</span>
                        <span class="p">])</span>

<span class="c1"># TODO: Consider if it is a good idea to have a method like `next_raw` which</span>
<span class="c1"># would just return tokens for raw characters.  This would be useful in</span>
<span class="c1"># parsing, say, C-style comments using the parser rather than a complicated</span>
<span class="c1"># regex.  Would need a special token kind to return for it.  This effectively</span>
<span class="c1"># modifies the token set scanned for, and would require flushing the buffer</span>
<span class="c1"># with go_back.  Other than that it should work. Not especially efficient to</span>
<span class="c1"># create a token for each char, but still linear in text size.</span>

<div class="viewcode-block" id="Lexer"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer">[docs]</a><span class="k">class</span> <span class="nc">Lexer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Scans text and returns tokens, represented by instances of `TokenNode`</span>
<span class="sd">    subclass instances. There is one subclass for each kind of token, i.e., for</span>
<span class="sd">    each token label.  These subclasses themselves are assumed to have been</span>
<span class="sd">    created before any scanning operation, via the `def_token` method.</span>

<span class="sd">    Token sequences are assumed to have both a begin-token and an end-token</span>
<span class="sd">    sentinel, defined via the `def_begin_end_tokens` method.  Exactly one</span>
<span class="sd">    end-token will be returned by `next`; any further calls to `next` raise</span>
<span class="sd">    `StopIteration`.</span>

<span class="sd">    The scanning is independent of the order in which tokens are defined.  The</span>
<span class="sd">    longest match over all token patterns will always be the one selected.  In</span>
<span class="sd">    case of ties the `on_ties` value (passed to `def_token`) is used to</span>
<span class="sd">    break it.  If that fails a `LexerException` is raised.</span>

<span class="sd">    If no token table is passed into `__init__` the `Lexer` will create its</span>
<span class="sd">    own empty one.&quot;&quot;&quot;</span>

    <span class="n">ERROR_MSG_TEXT_SNIPPET_SIZE</span> <span class="o">=</span> <span class="mi">40</span> <span class="c1"># Number of characters to show for context.</span>
    <span class="n">DEFAULT_BEGIN</span> <span class="o">=</span> <span class="s2">&quot;k_begin&quot;</span> <span class="c1"># Default label for begin-token.</span>
    <span class="n">DEFAULT_END</span> <span class="o">=</span> <span class="s2">&quot;k_end&quot;</span> <span class="c1"># Default label for end-token.</span>

    <span class="c1">#</span>
    <span class="c1"># Initialization methods</span>
    <span class="c1">#</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_table</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_peek_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">max_deque_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">default_begin_end_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">final_mod_function</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Initialize the Lexer.  Optional arguments set the `TokenTable` to be</span>
<span class="sd">        used (default creates a new one), the maximum number of lookahead</span>
<span class="sd">        tokens (default is no fixed maximum), and the maximum deque size, which</span>
<span class="sd">        determines how far `go_back` operations will work (the default is</span>
<span class="sd">        unlimited).</span>

<span class="sd">        If `default_begin_end_tokens` is true then begin- and end-tokens will</span>
<span class="sd">        be defined using the default token labels.  By default, though, the user</span>
<span class="sd">        must call the `def_begin_end_tokens` method to define the begin and</span>
<span class="sd">        end tokens (using whatever labels are desired).</span>

<span class="sd">        If `final_mod_function` is passed a function taking a two arguments</span>
<span class="sd">        then any time a token instance is created by the lexer that function</span>
<span class="sd">        will be called with the parser and the token itself as the two</span>
<span class="sd">        arguments.  It should return the modified token.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">token_table</span><span class="o">=</span><span class="n">token_table</span><span class="p">,</span> <span class="n">max_peek_tokens</span><span class="o">=</span><span class="n">max_peek_tokens</span><span class="p">,</span>
                   <span class="n">max_deque_size</span><span class="o">=</span><span class="n">max_deque_size</span><span class="p">,</span>
                   <span class="n">default_begin_end_tokens</span><span class="o">=</span><span class="n">default_begin_end_tokens</span><span class="p">,</span>
                   <span class="n">final_mod_function</span><span class="o">=</span><span class="n">final_mod_function</span><span class="p">)</span>

<div class="viewcode-block" id="Lexer.reset"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_table</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_peek_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">max_deque_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">default_begin_end_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">final_mod_function</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the lexer to the initial state.  Takes the same arguments as</span>
<span class="sd">        the initializer.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_is_set</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1">#self.all_token_count = None</span>

        <span class="k">if</span> <span class="n">token_table</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">token_table</span> <span class="o">=</span> <span class="n">TokenTable</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_token_table</span><span class="p">(</span><span class="n">token_table</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">max_deque_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">max_deque_size</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">max_peek_tokens</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">max_peek_tokens</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span> <span class="o">=</span> <span class="n">TokenBuffer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_unbuffered_token_getter</span><span class="p">,</span>
                                              <span class="n">max_peek</span><span class="o">=</span><span class="n">max_peek_tokens</span><span class="p">,</span>
                                              <span class="n">max_deque_size</span><span class="o">=</span><span class="n">max_deque_size</span><span class="p">)</span>

        <span class="c1"># These line and char numbers are for raw, unprocessed tokens, not the</span>
        <span class="c1"># buffered ones.  Use the values set with tokens as the token attribute</span>
        <span class="c1"># line_and_char (such as for the current token) for that info.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">raw_linenumber</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># The line number currently being read.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">upcoming_raw_charnumber</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># Char number of first char of upcoming token.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">upcoming_raw_total_chars</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># Like above, but total num., not on line.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">all_token_count</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">token_generator_state</span> <span class="o">=</span> <span class="n">GenTokenState</span><span class="o">.</span><span class="n">uninitialized</span>

        <span class="k">if</span> <span class="n">default_begin_end_tokens</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">def_begin_end_tokens</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEFAULT_BEGIN</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">DEFAULT_END</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">final_mod_function</span> <span class="o">=</span> <span class="n">final_mod_function</span>

        <span class="c1"># The default exception raised by methods like `match_next`.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_helper_exception</span> <span class="o">=</span> <span class="n">LexerException</span></div>

<div class="viewcode-block" id="Lexer.set_token_table"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.set_token_table">[docs]</a>    <span class="k">def</span> <span class="nf">set_token_table</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_table</span><span class="p">,</span> <span class="n">go_back</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets the current `TokenTable` instance for the lexer to</span>
<span class="sd">        `token_table`.  This is called on initialization, but can also be</span>
<span class="sd">        called at any time.  If text is being scanned at the time then it</span>
<span class="sd">        flushes the current and lookahead tokens and re-scans the current</span>
<span class="sd">        token.</span>

<span class="sd">        When set with this method the token table is always given the attribute</span>
<span class="sd">        `lex`, which points to the lexer instance that this method was called from.</span>
<span class="sd">        This attribute is used by tokens (which know their fixed symbol table)</span>
<span class="sd">        so they can find the current lexer (to call `next`, etc.)&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_table</span> <span class="o">=</span> <span class="n">token_table</span>
        <span class="n">token_table</span><span class="o">.</span><span class="n">lex</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_is_set</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">go_back</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># Re-scan the current token.</span></div>

<div class="viewcode-block" id="Lexer.set_text"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.set_text">[docs]</a>    <span class="k">def</span> <span class="nf">set_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">program</span><span class="p">,</span>
                 <span class="n">reset_linenumber</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reset_charnumber</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="c1"># TODO: redefine to take a TextStream.  Be sure to also pass back position</span>
        <span class="c1"># info with the returned text so that tokens have have their line/position</span>
        <span class="c1"># of origin pasted onto them..... or at least keep track in generating</span>
        <span class="c1"># tokens.</span>
        <span class="sd">&quot;&quot;&quot;Users should call this method to pass in the program text (or other</span>
<span class="sd">        text) which is to be lexically scanned.  The parameter `program` should</span>
<span class="sd">        be a string.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_table</span><span class="o">.</span><span class="n">begin_token_label</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_table</span><span class="o">.</span><span class="n">end_token_label</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s2">&quot;Begin and end tokens must be defined by calling&quot;</span>
                    <span class="s2">&quot; `def_begin_end_tokens` before set_text can be called.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">already_returned_end_token</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_curr_token_is_first</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># Is curr token first non-ignored in text?</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_returned_first_token</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Reset line, character, and token counts.  All counts include the buffer.</span>
        <span class="k">if</span> <span class="n">reset_linenumber</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">raw_linenumber</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">reset_charnumber</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">upcoming_raw_charnumber</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">upcoming_raw_total_chars</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_token_count</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># Count all actual tokens (not begin and end).</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">non_ignored_token_count</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># Count non-ignored actual tokens.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">program</span> <span class="o">=</span> <span class="n">program</span> <span class="c1"># The program text currently being scanned/lexed.</span>
        <span class="c1"># The prog_unprocessed list holds slice indices for the unprocessed part</span>
        <span class="c1"># of the program text.  The go_back routine can modify this.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="p">)]</span> <span class="c1"># The unprocessed slice.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_generator_state</span> <span class="o">=</span> <span class="n">GenTokenState</span><span class="o">.</span><span class="n">ordinary</span>

        <span class="c1"># Set up the token buffer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_token_buffer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># Last token returned; begin-token here.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_is_set</span> <span class="o">=</span> <span class="kc">True</span></div>

    <span class="k">def</span> <span class="nf">_initialize_token_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;A utility routine to initialize (fill) the token buffer.  The</span>
<span class="sd">        `token_buffer[0]` slot is the current token.  The current token will be</span>
<span class="sd">        set to the begin-token after this routine runs (since no tokens have</span>
<span class="sd">        yet been read with `next`).  Any tokens in the buffer past the first</span>
<span class="sd">        end-token are also set to end-tokens.  The size of the token buffer is</span>
<span class="sd">        `self.NUM_LOOKAHEAD_TOKENS` plus one for the current token.  For</span>
<span class="sd">        two-token lookahead the buffer deque has the form:</span>
<span class="sd">            [&lt;current_token&gt;, &lt;peek1&gt;, &lt;peek2&gt;]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">begin_tok</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_table</span><span class="o">.</span><span class="n">begin_token_subclass</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="c1"># Get instance.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_mod_function</span><span class="p">:</span>
            <span class="n">begin_tok</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_mod_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">begin_tok</span><span class="p">)</span>
        <span class="n">tb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">begin_tok</span><span class="p">)</span> <span class="c1"># Begin token set as current; first next() returns it.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token</span> <span class="o">=</span> <span class="n">tb</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">tb</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_begin_token</span><span class="p">()</span> <span class="c1"># DEBUG check, remove later</span>

    <span class="c1">#</span>
    <span class="c1"># Next and peek related methods</span>
    <span class="c1">#</span>

<div class="viewcode-block" id="Lexer.next"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.next">[docs]</a>    <span class="k">def</span> <span class="nf">next</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the next token, consuming from the token stream.  Also sets</span>
<span class="sd">        `self.token` to the return value.  Returns one end-token and raises</span>
<span class="sd">        `StopIteration` on a `next` after that end-token.</span>

<span class="sd">        If `num` is greater than one a list of the tokens is returned.  This</span>
<span class="sd">        list is cut short if the first end-token is encountered, so this</span>
<span class="sd">        kind of `next` call will never generate `StopIteration`.&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_is_set</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span>
                    <span class="s2">&quot;Attempt to call lexer&#39;s next method when no text is set.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">already_returned_end_token</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">text_is_set</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">raise</span> <span class="ne">StopIteration</span>

        <span class="c1"># Handle num &gt; 1 case with recursion.</span>
        <span class="k">if</span> <span class="n">num</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">ret_list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="o">.</span><span class="n">is_end_token</span><span class="p">():</span>
                    <span class="n">ret_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">next</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">break</span>
            <span class="k">return</span> <span class="n">ret_list</span>

        <span class="c1"># Handle ordinary case.</span>
        <span class="n">tb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token</span> <span class="o">=</span> <span class="n">tb</span><span class="o">.</span><span class="n">move_forward</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="o">.</span><span class="n">is_end_token</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">already_returned_end_token</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span></div>

    <span class="c1">#__next__ = next # For Python 3.</span>
    <span class="k">def</span> <span class="nf">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="c1"># NOTE: Cython needs this wrapper (instead of assignment) or else</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">next</span><span class="p">()</span> <span class="c1"># it doesn&#39;t think Lexer is an iterator.  But extra overhead.</span>

    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span> <span class="c1"># Class provides its own __next__ method.</span>

<div class="viewcode-block" id="Lexer.peek"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.peek">[docs]</a>    <span class="k">def</span> <span class="nf">peek</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_toks</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Peek ahead in the token stream without consuming any tokens.  The</span>
<span class="sd">        argument `num_toks` is the number of tokens ahead to peek.  The default</span>
<span class="sd">        peek of `num_toks=1` peeks at the token just beyond the current token.</span>
<span class="sd">        Peeking zero shows the current token.  Negative peeks are allowed, and</span>
<span class="sd">        look back at the previous tokens (up to the number saved in the token</span>
<span class="sd">        buffer).</span>

<span class="sd">        Tokens are read into the buffer on-demand to satisfy any requested</span>
<span class="sd">        peek.  If `max_peek_tokens` is set then an exception will be raised on</span>
<span class="sd">        attempts to peek farther than that.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_is_set</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span>
                    <span class="s2">&quot;Attempt to call lexer&#39;s peek method when no text is set.&quot;</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">retval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">[</span><span class="n">num_toks</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span> <span class="c1"># Shouldn&#39;t happen.</span>
            <span class="k">raise</span> <span class="n">BufferIndexError</span>
        <span class="k">return</span> <span class="n">retval</span></div>

<div class="viewcode-block" id="Lexer.move_back"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.move_back">[docs]</a>    <span class="k">def</span> <span class="nf">move_back</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_toks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_is_raw</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;NOT YET IMPLEMENTED</span>

<span class="sd">        Move the current token back in the token stream.  This method is</span>
<span class="sd">        similar to methods commonly called `push_back`. It is similar to</span>
<span class="sd">        `go_back` except that tokens are not rescanned.  The current position</span>
<span class="sd">        in the token buffer is just moved back.  This is more efficient than</span>
<span class="sd">        `go_back` but it assumes that there have been no modifications,</span>
<span class="sd">        additions, or deletions to the token definitions.  If the parser is</span>
<span class="sd">        guaranteed to be static with respect to the defined tokens then this is</span>
<span class="sd">        the routine to use.  Otherwise, use `go_back`.</span>

<span class="sd">        The optional parameter `num_toks` is the number of tokens to move</span>
<span class="sd">        back.  Negative numbers move forward, consuming more tokens if</span>
<span class="sd">        necessary.  Moving forward will always stop before consuming a second</span>
<span class="sd">        end-token (which would raise `StopIteration` if done in `next`).&quot;&quot;&quot;</span>
        <span class="c1"># TODO: Implement.  Shouldn&#39;t be too hard, but it might need to modify</span>
        <span class="c1"># some of the Lexer attributes.  Remember, though, that the line and</span>
        <span class="c1"># char number in the lexer class are for the latest *unbuffered* token.</span>
        <span class="c1">#</span>
        <span class="c1"># TODO use the token buffer&#39;s move_forward and move_back methods;</span>
        <span class="c1"># finish implementing them...</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_is_set</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span>
                    <span class="s2">&quot;Attempt to call lexer&#39;s move_back method when no text is set.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_generator_state</span> <span class="o">==</span> <span class="n">GenTokenState</span><span class="o">.</span><span class="n">uninitialized</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s2">&quot;The token generator has not been initialized &quot;</span>
                  <span class="s2">&quot;or has reached `StopIteration` by reading past the end-token.&quot;</span><span class="p">)</span>

        <span class="n">token_buffer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span></div>

    <span class="k">def</span> <span class="nf">_pop_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Pop `n` tokens from the token buffer, resetting the slice indices in</span>
<span class="sd">        `self.prog_unprocessed` and other state variables.  Used by `go_back`.&quot;&quot;&quot;</span>
        <span class="n">popped_to_begin_token</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">current_token_is_first</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">token_buffer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span>

            <span class="k">if</span> <span class="n">token_buffer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_begin_token</span><span class="p">():</span>
                <span class="n">popped_to_begin_token</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">return</span> <span class="n">popped_to_begin_token</span><span class="p">,</span> <span class="n">current_token_is_first</span>

            <span class="n">popped</span> <span class="o">=</span> <span class="n">token_buffer</span><span class="o">.</span><span class="n">_pop</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">popped</span><span class="o">.</span><span class="n">is_end_token</span><span class="p">():</span>
                <span class="k">continue</span> <span class="c1"># No actual text was read for end tokens.</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">non_ignored_token_count</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">all_token_count</span> <span class="o">-=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">popped</span><span class="o">.</span><span class="n">ignored_before</span><span class="p">))</span>

            <span class="c1"># Reset the line number information.</span>
            <span class="k">if</span> <span class="n">popped</span><span class="o">.</span><span class="n">ignored_before</span><span class="p">:</span>
                <span class="n">line_and_char</span> <span class="o">=</span> <span class="n">popped</span><span class="o">.</span><span class="n">ignored_before</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">line_and_char</span>
                <span class="n">char_index_in_program</span> <span class="o">=</span> <span class="n">popped</span><span class="o">.</span><span class="n">ignored_before</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">char_index_in_program</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">line_and_char</span> <span class="o">=</span> <span class="n">popped</span><span class="o">.</span><span class="n">line_and_char</span>
                <span class="n">char_index_in_program</span> <span class="o">=</span> <span class="n">popped</span><span class="o">.</span><span class="n">char_index_in_program</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">raw_linenumber</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">upcoming_raw_charnumber</span> <span class="o">=</span> <span class="n">line_and_char</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">upcoming_raw_total_chars</span> <span class="o">=</span> <span class="n">char_index_in_program</span>

            <span class="c1"># Reset the slice indices into the program text.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-=</span> <span class="nb">len</span><span class="p">(</span><span class="n">popped</span><span class="o">.</span><span class="n">original_matched_string</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">token_buffer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">is_begin_token</span><span class="p">():</span>
                <span class="n">current_token_is_first</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">popped_to_begin_token</span><span class="p">,</span> <span class="n">current_token_is_first</span>

<div class="viewcode-block" id="Lexer.go_back"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.go_back">[docs]</a>    <span class="k">def</span> <span class="nf">go_back</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_toks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_is_raw</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This method allows the lexer to go back in the token buffer by</span>
<span class="sd">        `num_toks` tokens.  The call `go_back(n)` will undo the effects of the</span>
<span class="sd">        last `n` calls to `next`.  This operation is different from the usual</span>
<span class="sd">        pushback operations because the program text will be re-scanned for the</span>
<span class="sd">        current token and later tokens (rather than simply backing up to</span>
<span class="sd">        already-scanned tokens and saving the most-recent as lookahead tokens,</span>
<span class="sd">        like with `move_back`).</span>

<span class="sd">        Going back one with `go_back(1)` or just `go_back()` results in the</span>
<span class="sd">        current token being set back to the previous token and also re-scanned</span>
<span class="sd">        from the original text.  Calling `go_back(0)` just re-scans the current</span>
<span class="sd">        token (and flushes any tokens in the lookahead buffer).  Values greater</span>
<span class="sd">        than one go farther back in the token stream.  Attempts to go back</span>
<span class="sd">        before the beginning of the program text go back to the beginning and</span>
<span class="sd">        stop there.</span>

<span class="sd">        This method returns the current token after any re-scanning.</span>

<span class="sd">        Negative numbers of tokens can be specified.  When `num_toks &lt;= 0` the</span>
<span class="sd">        operation only applies to saved loohahead tokens (if there are any).</span>
<span class="sd">        The call `go_back(-1)` flushes all lookahead tokens saved in the buffer</span>
<span class="sd">        except the one immediately following the current token.  The current</span>
<span class="sd">        offset in the token buffer never moves forward when this method is</span>
<span class="sd">        called; only can only go back or stay the same.</span>

<span class="sd">        If `num_is_raw` is true then `num_toks` is interpreted as the actual</span>
<span class="sd">        number of tokens to go back, including any in the buffer (which are</span>
<span class="sd">        otherwise handled automatically).  This can be useful when looking at</span>
<span class="sd">        `lex.all_token_count` to determine how far to go back and undo</span>
<span class="sd">        something.</span>

<span class="sd">        Going back with re-scanning can be necessary when token definitions</span>
<span class="sd">        themselves change dynamically, such as by semantic actions.  For</span>
<span class="sd">        example, a declaration of the string &quot;my_fun&quot; as a variable might</span>
<span class="sd">        dynamically add a token for that new variable, which would then stop it</span>
<span class="sd">        from matching a general identifier with a lower on_ties value (set to,</span>
<span class="sd">        say, -1).  This kind of thing is also needed when swapping token</span>
<span class="sd">        tables, such as in parsing a sublanguage with a different parser.</span>
<span class="sd">        Since the sublanguage has a different collection of tokens the</span>
<span class="sd">        lookahead buffer must be re-scanned based on those tokens.&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_is_set</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span>
                    <span class="s2">&quot;Attempt to call lexer&#39;s go_back method when no text is set.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_generator_state</span> <span class="o">==</span> <span class="n">GenTokenState</span><span class="o">.</span><span class="n">uninitialized</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s2">&quot;The token generator has not been initialized &quot;</span>
                  <span class="s2">&quot;or has reached `StopIteration` by reading past the end-token.&quot;</span><span class="p">)</span>

        <span class="n">token_buffer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span> <span class="c1"># Shorter alias.</span>

        <span class="c1"># For negative values just pop the required number off the end of token_buffer.</span>
        <span class="k">if</span> <span class="n">num_toks</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">peekahead_num</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">num_toks</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;the peekahead num is:&quot;</span><span class="p">,</span> <span class="n">peekahead_num</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_pop_tokens</span><span class="p">(</span><span class="n">token_buffer</span><span class="o">.</span><span class="n">num_tokens_after_current</span><span class="p">()</span> <span class="o">-</span> <span class="n">peekahead_num</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;returning token with value:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span>

        <span class="c1"># We will re-scan at least one token, so reset `already_returned_end_token`.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">already_returned_end_token</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">num_buffered_after_current</span> <span class="o">=</span> <span class="n">token_buffer</span><span class="o">.</span><span class="n">num_tokens_after_current</span><span class="p">()</span>
        <span class="n">num_to_pop</span> <span class="o">=</span> <span class="n">num_toks</span> <span class="o">+</span> <span class="n">num_buffered_after_current</span> <span class="o">+</span> <span class="mi">1</span> <span class="c1"># new curr is rescanned</span>

        <span class="k">if</span> <span class="n">num_is_raw</span><span class="p">:</span>
            <span class="c1"># Works with lex.all_token_count in production_rules, but why +2?</span>
            <span class="c1"># Setting max_peek_tokens doesn&#39;t affect it.  Clean up code.</span>
            <span class="n">num_to_pop</span> <span class="o">=</span> <span class="n">num_toks</span> <span class="o">+</span> <span class="mi">2</span> <span class="c1"># The added number doesn&#39;t matter except when it does...</span>

        <span class="n">popped_to_begin_token</span><span class="p">,</span> <span class="n">current_token_is_first</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pop_tokens</span><span class="p">(</span><span class="n">num_to_pop</span><span class="p">)</span>

        <span class="c1"># Re-scan to get the new current token.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">popped_to_begin_token</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

        <span class="c1"># Reset some state variables.</span>
        <span class="k">if</span> <span class="n">popped_to_begin_token</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">peek</span><span class="p">()</span><span class="o">.</span><span class="n">is_first</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_returned_first_token</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_curr_token_is_first</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="n">current_token_is_first</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="o">.</span><span class="n">is_first</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_returned_first_token</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_curr_token_is_first</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">already_returned_end_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="o">.</span><span class="n">is_end_token</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span></div>

<div class="viewcode-block" id="Lexer.get_current_state"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.get_current_state">[docs]</a>    <span class="k">def</span> <span class="nf">get_current_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get a lexer state that can be returned to with `go_back_to_state`.</span>
<span class="sd">        States become invalid after the text is reset, but no check is made.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span></div>

<div class="viewcode-block" id="Lexer.go_back_to_state"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.go_back_to_state">[docs]</a>    <span class="k">def</span> <span class="nf">go_back_to_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the lexer to the state `state` saved from a previous call to</span>
<span class="sd">        `get_current_state`.&quot;&quot;&quot;</span>
        <span class="n">index_to_go_back_to</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="o">.</span><span class="n">state_to_offset</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">num_to_go_back</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="o">.</span><span class="n">current_offset</span> <span class="o">-</span> <span class="n">index_to_go_back_to</span>
        <span class="k">if</span> <span class="n">num_to_go_back</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">next</span><span class="p">(</span><span class="o">-</span><span class="n">num_to_go_back</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">go_back</span><span class="p">(</span><span class="n">num_to_go_back</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span></div>

    <span class="c1">#</span>
    <span class="c1"># Informational methods</span>
    <span class="c1">#</span>

<div class="viewcode-block" id="Lexer.curr_token_is_begin"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.curr_token_is_begin">[docs]</a>    <span class="k">def</span> <span class="nf">curr_token_is_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;True if `self.token` (the last one returned by the `next` method) is</span>
<span class="sd">        the begin-token.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="o">.</span><span class="n">is_begin_token</span><span class="p">()</span></div>

<div class="viewcode-block" id="Lexer.curr_token_is_first"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.curr_token_is_first">[docs]</a>    <span class="k">def</span> <span class="nf">curr_token_is_first</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;True if `self.token` (the last one returned by the `next` function)</span>
<span class="sd">        is the first actual token in the currently-set program text.  Resetting</span>
<span class="sd">        the text resets this.  This value is also set as the attribute</span>
<span class="sd">        `is_first` on all returned tokens.  This is useful, for example, for</span>
<span class="sd">        finding indentation levels (along with `ignored_before_curr`).&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="o">.</span><span class="n">is_first</span></div>

<div class="viewcode-block" id="Lexer.ignored_before_curr"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.ignored_before_curr">[docs]</a>    <span class="k">def</span> <span class="nf">ignored_before_curr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the list of all tokens ignored just before `self.token` (the</span>
<span class="sd">        last token returned by the `next` function).  Useful for enforcing</span>
<span class="sd">        things like syntactic whitespace requirements, along with</span>
<span class="sd">        `curr_token_is_first`. This list is also set as the attribute</span>
<span class="sd">        `ignored_before_tokens` on all returned tokens.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="o">.</span><span class="n">ignored_before</span></div>

<div class="viewcode-block" id="Lexer.curr_token_is_end"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.curr_token_is_end">[docs]</a>    <span class="k">def</span> <span class="nf">curr_token_is_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;True if `self.token` (the last one returned by the `next` method) is</span>
<span class="sd">        the end-token.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="o">.</span><span class="n">is_end_token</span><span class="p">()</span></div>

<div class="viewcode-block" id="Lexer.is_defined_token_label"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.is_defined_token_label">[docs]</a>    <span class="k">def</span> <span class="nf">is_defined_token_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return true if `token` is currently defined as a token label.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_table</span><span class="o">.</span><span class="n">is_defined_token_label</span><span class="p">()</span></div>

<div class="viewcode-block" id="Lexer.last_n_tokens_original_text"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.last_n_tokens_original_text">[docs]</a>    <span class="k">def</span> <span class="nf">last_n_tokens_original_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the original text parsed by the last `n` tokens (back from</span>
<span class="sd">        and including the current token).  This routine is mainly used to make</span>
<span class="sd">        error messages more helpful.  It uses the token attribute</span>
<span class="sd">        `original_matched_string` and the saved tokens in the token buffer.</span>
<span class="sd">        (which must be large enough for `n`).&quot;&quot;&quot;</span>
        <span class="c1"># TODO: Test this, code updated to use token_buffer class.</span>
        <span class="c1"># Could also print line numbers and stuff....</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="o">.</span><span class="n">num_saved_previous_tokens</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">prev_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="n">string_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">original_matched_string</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">prev_tokens</span><span class="p">]</span>
        <span class="n">full_string</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">string_list</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">full_string</span></div>

<div class="viewcode-block" id="Lexer.get_unprocessed_text"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.get_unprocessed_text">[docs]</a>    <span class="k">def</span> <span class="nf">get_unprocessed_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">peek</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return all the text that is set but not yet processed.  Returns</span>
<span class="sd">        `None` if no text is currently set.  The current token is assumed</span>
<span class="sd">        to have been processed.</span>

<span class="sd">        By default this is relative to the token at a peek of `1`, but the</span>
<span class="sd">        `peek` number can be set to a previous or later one if available in the</span>
<span class="sd">        buffer.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_is_set</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="n">text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">peek</span><span class="p">(</span><span class="n">peek</span><span class="p">)</span><span class="o">.</span><span class="n">char_index_in_program</span><span class="p">:]</span>
        <span class="k">return</span> <span class="n">text</span></div>

<div class="viewcode-block" id="Lexer.get_processed_text"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.get_processed_text">[docs]</a>    <span class="k">def</span> <span class="nf">get_processed_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">peek</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return all the text that is set and has been processed.  Returns</span>
<span class="sd">        `None` if no text is currently set.  The current token is assumed</span>
<span class="sd">        to have been processed.</span>

<span class="sd">        By default this is relative to the current peek token, but the `peek`</span>
<span class="sd">        number can be set to a previous or later one if available in the</span>
<span class="sd">        buffer.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_is_set</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="n">text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">peek</span><span class="p">(</span><span class="n">peek</span><span class="p">)</span><span class="o">.</span><span class="n">char_index_in_program</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">text</span></div>

    <span class="c1">#</span>
    <span class="c1"># Methods to define and undefine tokens</span>
    <span class="c1">#</span>

<div class="viewcode-block" id="Lexer.def_token"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.def_token">[docs]</a>    <span class="k">def</span> <span class="nf">def_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">,</span> <span class="n">regex_string</span><span class="p">,</span> <span class="n">on_ties</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignore</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                  <span class="n">matcher_options</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;A convenience method to define a token. It calls the corresponding</span>
<span class="sd">        `def_token` method of the current `TokenTable` instance associated with</span>
<span class="sd">        the lexer, and does nothing else.&quot;&quot;&quot;</span>
        <span class="n">new_subclass</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_table</span><span class="o">.</span><span class="n">def_token</span><span class="p">(</span><span class="n">token_label</span><span class="p">,</span> <span class="n">regex_string</span><span class="p">,</span>
                    <span class="n">on_ties</span><span class="o">=</span><span class="n">on_ties</span><span class="p">,</span> <span class="n">ignore</span><span class="o">=</span><span class="n">ignore</span><span class="p">,</span> <span class="n">matcher_options</span><span class="o">=</span><span class="n">matcher_options</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_subclass</span></div>

<div class="viewcode-block" id="Lexer.undef_token"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.undef_token">[docs]</a>    <span class="k">def</span> <span class="nf">undef_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;A convenience function to call the corresponding `undef_token` of</span>
<span class="sd">        the current `TokenTable` instance associated with the Lexer.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_table</span><span class="o">.</span><span class="n">undef_token</span><span class="p">(</span><span class="n">token_label</span><span class="p">)</span></div>

<div class="viewcode-block" id="Lexer.def_ignored_token"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.def_ignored_token">[docs]</a>    <span class="k">def</span> <span class="nf">def_ignored_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">,</span> <span class="n">regex_string</span><span class="p">,</span> <span class="n">on_ties</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                          <span class="n">matcher_options</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;A convenience function to define an ignored token without setting</span>
<span class="sd">        `ignore=True`.  This just calls `def_token` with the value set.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">def_token</span><span class="p">(</span><span class="n">token_label</span><span class="p">,</span> <span class="n">regex_string</span><span class="p">,</span> <span class="n">on_ties</span><span class="o">=</span><span class="n">on_ties</span><span class="p">,</span> <span class="n">ignore</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                              <span class="n">matcher_options</span><span class="o">=</span><span class="n">matcher_options</span><span class="p">)</span></div>

<div class="viewcode-block" id="Lexer.def_multi_tokens"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.def_multi_tokens">[docs]</a>    <span class="k">def</span> <span class="nf">def_multi_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tuple_list</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;A convenience function, to define multiple tokens at once.  Each element</span>
<span class="sd">        of the passed-in list should be a tuple containing the arguments to the</span>
<span class="sd">        ordinary `def_token` method.  Called in the same order as the list.  Any</span>
<span class="sd">        keyword arguments are passed on to `def_token`.  Returns a tuple of the</span>
<span class="sd">        defined tokens.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">multi_funcall</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">def_token</span><span class="p">,</span> <span class="n">tuple_list</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Lexer.def_multi_ignored_tokens"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.def_multi_ignored_tokens">[docs]</a>    <span class="k">def</span> <span class="nf">def_multi_ignored_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tuple_list</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;A convenience function, to define multiple tokens at once with</span>
<span class="sd">        `ignore=True` set.  Each element of the passed-in list should be a tuple</span>
<span class="sd">        containing the arguments to the ordinary `def_token` method.  Called in</span>
<span class="sd">        the same order as the list.  Any keyword arguments are passed on to</span>
<span class="sd">        `def_token`.  Returns a tuple of the defined tokens.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">multi_funcall</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">def_ignored_token</span><span class="p">,</span> <span class="n">tuple_list</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Lexer.def_begin_end_tokens"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.def_begin_end_tokens">[docs]</a>    <span class="k">def</span> <span class="nf">def_begin_end_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">begin_token_label</span><span class="p">,</span> <span class="n">end_token_label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Define the sentinel tokens at the beginning and end of the token</span>
<span class="sd">        stream.  This method must be called before using the Lexer.  It will</span>
<span class="sd">        automatically be called using default token label values unless</span>
<span class="sd">        `default_begin_end_tokens` was set false on initialization.  Returns a</span>
<span class="sd">        tuple of the new begin- and end-token subclasses.  These tokens do not</span>
<span class="sd">        need to be defined with `def_token` because they are never actually</span>
<span class="sd">        scanned and recognized in the program text (which would also require a</span>
<span class="sd">        regex pattern).&quot;&quot;&quot;</span>
        <span class="c1"># TODO: consider if begin and end tokens should be created by a</span>
        <span class="c1"># token_table method.  Probably they should, but then in Lexer need</span>
        <span class="c1"># to change all the self.begin_token_label to have self.token_table</span>
        <span class="c1"># prefix.</span>
        <span class="n">begin_tok</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_table</span><span class="o">.</span><span class="n">def_begin_token</span><span class="p">(</span><span class="n">begin_token_label</span><span class="p">)</span>
        <span class="n">end_tok</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_table</span><span class="o">.</span><span class="n">def_end_token</span><span class="p">(</span><span class="n">end_token_label</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">begin_tok</span><span class="p">,</span> <span class="n">end_tok</span></div>

<div class="viewcode-block" id="Lexer.def_default_whitespace"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.def_default_whitespace">[docs]</a>    <span class="k">def</span> <span class="nf">def_default_whitespace</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">space_label</span><span class="o">=</span><span class="s2">&quot;k_space&quot;</span><span class="p">,</span> <span class="n">space_regex</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;[ \t]+&quot;</span><span class="p">,</span>
                        <span class="n">newline_label</span><span class="o">=</span><span class="s2">&quot;k_newline&quot;</span><span class="p">,</span> <span class="n">newline_regex</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;[\n\f\r\v]+&quot;</span><span class="p">,</span>
                        <span class="n">matcher_options</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Define the standard whitespace tokens for space and newline, setting</span>
<span class="sd">        them as ignored tokens.&quot;&quot;&quot;</span>
        <span class="n">tok</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">def_ignored_token</span>
        <span class="n">tok</span><span class="p">(</span><span class="n">space_label</span><span class="p">,</span> <span class="n">space_regex</span><span class="p">,</span> <span class="n">matcher_options</span><span class="o">=</span><span class="n">matcher_options</span><span class="p">)</span>
        <span class="n">tok</span><span class="p">(</span><span class="n">newline_label</span><span class="p">,</span> <span class="n">newline_regex</span><span class="p">,</span> <span class="n">matcher_options</span><span class="o">=</span><span class="n">matcher_options</span><span class="p">)</span></div>

    <span class="c1">#</span>
    <span class="c1"># Some helper functions when using the Lexer class.</span>
    <span class="c1">#</span>

<div class="viewcode-block" id="Lexer.match_next"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.match_next">[docs]</a>    <span class="k">def</span> <span class="nf">match_next</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label_to_match</span><span class="p">,</span> <span class="n">peeklevel</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">consume</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">raise_on_fail</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">raise_on_success</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                   <span class="n">err_msg_tokens</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="c1"># TODO: Consider a way for users to define custom error strings for</span>
        <span class="c1"># better error-reporting.</span>
        <span class="sd">&quot;&quot;&quot;A utility function that tests whether the value of the next token</span>
<span class="sd">        label equals a given token label.</span>

<span class="sd">        This method consumes a token from the lexer if and only if there is a</span>
<span class="sd">        match.  Either way, a boolean is returned indicating the match status.</span>

<span class="sd">        If `consume` is false then no tokens will ever be consumed.  Otherwise,</span>
<span class="sd">        and by default, a token will be consumed if and only if it matches.</span>

<span class="sd">        The parameter `peeklevel` is passed to the peek function for how far</span>
<span class="sd">        ahead to look; the default is one.</span>

<span class="sd">        If `raise_on_fail` set true then a `LexerException` will be raised by</span>
<span class="sd">        default if the match fails.  The default can be changed by setting the</span>
<span class="sd">        lexer instance attribute `default_helper_exception`.  Similarly,</span>
<span class="sd">        `raise_on_success` raises an exception when a match is found.  Either one</span>
<span class="sd">        can be set to a subclass of `Exception` instead of a boolean, and then</span>
<span class="sd">        that exception will be called.</span>

<span class="sd">        The parameter `err_msg_tokens` can be set to change how many tokens</span>
<span class="sd">        worth of text back the error messages report (as debugging</span>
<span class="sd">        information) when an exception is raised.  (The count does not</span>
<span class="sd">        include whitespace, but it is printed, too.)&quot;&quot;&quot;</span>
        <span class="n">retval</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">token_label_to_match</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">peek</span><span class="p">(</span><span class="n">peeklevel</span><span class="p">)</span><span class="o">.</span><span class="n">token_label</span><span class="p">:</span>
            <span class="n">retval</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">consume</span> <span class="ow">and</span> <span class="n">retval</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">next</span><span class="p">()</span> <span class="c1"># Eat the token that was matched.</span>

        <span class="k">if</span> <span class="n">retval</span> <span class="ow">and</span> <span class="n">raise_on_success</span><span class="p">:</span>
            <span class="n">exception</span> <span class="o">=</span> <span class="n">return_first_exception</span><span class="p">(</span><span class="n">raise_on_success</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">default_helper_exception</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">exception</span><span class="p">(</span>
                    <span class="s2">&quot;Function match_next (with peeklevel=</span><span class="si">{0}</span><span class="s2">) found unexpected &quot;</span>
                    <span class="s2">&quot;token </span><span class="si">{1}</span><span class="s2">.  The text of the </span><span class="si">{2}</span><span class="s2"> tokens up to &quot;</span>
                    <span class="s2">&quot;the error is: </span><span class="si">{3}</span><span class="s2">&quot;</span> <span class="c1"># TODO fix below, fails with parser</span>
                    <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">peeklevel</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">peek</span><span class="p">(</span><span class="n">peeklevel</span><span class="p">)),</span> <span class="n">err_msg_tokens</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">last_n_tokens_original_text</span><span class="p">(</span><span class="n">err_msg_tokens</span><span class="p">)))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">retval</span> <span class="ow">and</span> <span class="n">raise_on_fail</span><span class="p">:</span>
            <span class="n">exception</span> <span class="o">=</span> <span class="n">return_first_exception</span><span class="p">(</span><span class="n">raise_on_fail</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">default_helper_exception</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">exception</span><span class="p">(</span>
                    <span class="s2">&quot;Function match_next (with peeklevel=</span><span class="si">{0}</span><span class="s2">) expected token &quot;</span>
                    <span class="s2">&quot;with label &#39;</span><span class="si">{1}</span><span class="s2">&#39; but found token </span><span class="si">{2}</span><span class="s2">.  The text parsed &quot;</span>
                    <span class="s2">&quot;from the tokens up to the error is: </span><span class="si">{3}</span><span class="s2">&quot;</span> <span class="c1"># TODO fix below, fails</span>
                    <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">peeklevel</span><span class="p">,</span> <span class="n">token_label_to_match</span><span class="p">,</span>
                            <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">peek</span><span class="p">(</span><span class="n">peeklevel</span><span class="p">)),</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">last_n_tokens_original_text</span><span class="p">(</span><span class="n">err_msg_tokens</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">retval</span></div>

    <span class="c1"># TODO document these utilities......</span>
<div class="viewcode-block" id="Lexer.in_ignored_tokens"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.in_ignored_tokens">[docs]</a>    <span class="k">def</span> <span class="nf">in_ignored_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label_to_match</span><span class="p">,</span>
                          <span class="n">raise_on_fail</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">raise_on_success</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;A utility function to test if a particular token label is among</span>
<span class="sd">        the tokens ignored before the current token.  Returns a boolean</span>
<span class="sd">        value.  Like `match_next`, this method can be set to raise an</span>
<span class="sd">        exception on success or failure.&quot;&quot;&quot;</span>
        <span class="n">retval</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">ignored_token_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">token_label</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">peek</span><span class="p">()</span><span class="o">.</span><span class="n">ignored_before</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">token_label_to_match</span> <span class="ow">in</span> <span class="n">ignored_token_labels</span><span class="p">:</span>
            <span class="n">retval</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="n">retval</span> <span class="ow">and</span> <span class="n">raise_on_success</span><span class="p">:</span>
            <span class="n">exception</span> <span class="o">=</span> <span class="n">return_first_exception</span><span class="p">(</span><span class="n">raise_on_success</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">default_helper_exception</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">exception</span><span class="p">(</span>
                    <span class="s2">&quot;Function in_ignored_tokens found unexpected token with &quot;</span>
                    <span class="s2">&quot;label &#39;</span><span class="si">{0}</span><span class="s2">&#39; before the current token </span><span class="si">{1}</span><span class="s2">.&quot;</span>
                    <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">token_label_to_match</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="p">)))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">retval</span> <span class="ow">and</span> <span class="n">raise_on_fail</span><span class="p">:</span>
            <span class="n">exception</span> <span class="o">=</span> <span class="n">return_first_exception</span><span class="p">(</span><span class="n">raise_on_fail</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">default_helper_exception</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">exception</span><span class="p">(</span>
                    <span class="s2">&quot;Function in_ignored_tokens expected token with label &quot;</span>
                    <span class="s2">&quot;&#39;</span><span class="si">{0}</span><span class="s2">&#39; before the current token </span><span class="si">{1}</span><span class="s2">, but it was not found.&quot;</span>
                    <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">token_label_to_match</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">retval</span></div>

<div class="viewcode-block" id="Lexer.no_ignored_after"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.no_ignored_after">[docs]</a>    <span class="k">def</span> <span class="nf">no_ignored_after</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">raise_on_fail</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">raise_on_success</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;A boolean utility function to test if any tokens were ignored</span>
<span class="sd">        between current token and lookahead.  Like `match_next`, this method</span>
<span class="sd">        can be set to raise an exception on success or failure.&quot;&quot;&quot;</span>
        <span class="n">retval</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">peek</span><span class="p">()</span><span class="o">.</span><span class="n">ignored_before</span><span class="p">:</span>
            <span class="n">retval</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">retval</span> <span class="ow">and</span> <span class="n">raise_on_success</span><span class="p">:</span>
            <span class="n">exception</span> <span class="o">=</span> <span class="n">return_first_exception</span><span class="p">(</span><span class="n">raise_on_success</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">default_helper_exception</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">exception</span><span class="p">(</span>
                    <span class="s2">&quot;Function no_ignored_after expected tokens between the current &quot;</span>
                    <span class="s2">&quot;token </span><span class="si">{0}</span><span class="s2"> and the following token </span><span class="si">{1}</span><span class="s2">, but there were none.&quot;</span>
                    <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">peek</span><span class="p">())))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">retval</span> <span class="ow">and</span> <span class="n">raise_on_fail</span><span class="p">:</span>
            <span class="n">exception</span> <span class="o">=</span> <span class="n">return_first_exception</span><span class="p">(</span><span class="n">raise_on_fail</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">default_helper_exception</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">exception</span><span class="p">(</span>
                    <span class="s2">&quot;Function no_ignored_after expected nothing between the &quot;</span>
                    <span class="s2">&quot;current token </span><span class="si">{0}</span><span class="s2"> and the following token </span><span class="si">{1}</span><span class="s2">, but there &quot;</span>
                    <span class="s2">&quot;were ignored tokens.&quot;</span>
                    <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">peek</span><span class="p">())))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">retval</span></div>

<div class="viewcode-block" id="Lexer.no_ignored_before"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.Lexer.no_ignored_before">[docs]</a>    <span class="k">def</span> <span class="nf">no_ignored_before</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">raise_on_fail</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">raise_on_success</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;A boolean utility function to test if any tokens were ignored between</span>
<span class="sd">        previous token and current token.  Like `match_next`, this method</span>
<span class="sd">        can be set to raise an exception on success or failure.&quot;&quot;&quot;</span>
        <span class="n">retval</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="o">.</span><span class="n">ignored_before</span><span class="p">:</span>
            <span class="n">retval</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">retval</span> <span class="ow">and</span> <span class="n">raise_on_success</span><span class="p">:</span>
            <span class="n">exception</span> <span class="o">=</span> <span class="n">return_first_exception</span><span class="p">(</span><span class="n">raise_on_success</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">default_helper_exception</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">exception</span><span class="p">(</span>
                    <span class="s2">&quot;Function no_ignored_before expected ignored tokens before &quot;</span>
                    <span class="s2">&quot; the current token </span><span class="si">{0}</span><span class="s2">, but none were found.&quot;</span>
                    <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="p">)))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">retval</span> <span class="ow">and</span> <span class="n">raise_on_fail</span><span class="p">:</span>
            <span class="n">exception</span> <span class="o">=</span> <span class="n">return_first_exception</span><span class="p">(</span><span class="n">raise_on_fail</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">default_helper_exception</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">exception</span><span class="p">(</span>
                    <span class="s2">&quot;Function no_ignored_before expected no ignored tokens &quot;</span>
                    <span class="s2">&quot;before the current token </span><span class="si">{0}</span><span class="s2">, but at least one was found.&quot;</span>
                    <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">retval</span></div>

    <span class="c1">#</span>
    <span class="c1"># Lower-level routine for token generation</span>
    <span class="c1">#</span>

    <span class="k">def</span> <span class="nf">_unbuffered_token_getter</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This routine generates tokens from the program text in the attribute</span>
<span class="sd">        `self.program`.  It does not modify the program itself, but keeps slice</span>
<span class="sd">        indices in a list `self.prog_unprocessed` indexing the unprocessed</span>
<span class="sd">        part.  That slice can be externally modified (the `go_back` routine</span>
<span class="sd">        does this).</span>

<span class="sd">        This is a lower-level function used by `next` to do the real work.  All</span>
<span class="sd">        the token subclasses should have been defined and stored in the the</span>
<span class="sd">        `TokenTable`.  Regexes defined for tokens are repeatedly matched at the</span>
<span class="sd">        beinning of the string `program`.  When a winning_index is found it is</span>
<span class="sd">        stripped off the beginning of the unprocessed slice of `program`.  For</span>
<span class="sd">        each winning_index the token subclass is looked up in the `TokenTable`</span>
<span class="sd">        object and an instance of that subclass is returned to represent the</span>
<span class="sd">        token.  Every token processed is represented by a unique new instance</span>
<span class="sd">        of the appropriate subclass of `TokenNode`.</span>

<span class="sd">        This generator has two states which can be set instance-globally to</span>
<span class="sd">        alter the state of the generator.  The states are</span>
<span class="sd">        `GenTokenState.ordinary` for ordinary scanning execution, and</span>
<span class="sd">        `GenTokenState.end` when all the tokens have been read.  In the</span>
<span class="sd">        `GenTokenState.end` state the method returns nothing but end tokens.</span>
<span class="sd">        The end state is normally entered when the program text becomes empty.</span>
<span class="sd">        If that variable is later is set to have text again the state switches</span>
<span class="sd">        back to ordinary.  (The lexer&#39;s `next` routine handles any raising of</span>
<span class="sd">        `StopIteration`.)&quot;&quot;&quot;</span>
        <span class="n">ignored_before_labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">ignored_before_tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">original_matched_string</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="n">token_table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_table</span>

        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_curr_token_is_first</span> <span class="o">=</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_returned_first_token</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_returned_first_token</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">token_generator_state</span> <span class="o">=</span> <span class="n">GenTokenState</span><span class="o">.</span><span class="n">end</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">token_generator_state</span> <span class="o">=</span> <span class="n">GenTokenState</span><span class="o">.</span><span class="n">ordinary</span>

            <span class="n">first_after_newline</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="c1"># =======================================================================</span>
            <span class="c1"># === Ordinary execution state ==========================================</span>
            <span class="c1"># =======================================================================</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_generator_state</span> <span class="o">==</span> <span class="n">GenTokenState</span><span class="o">.</span><span class="n">ordinary</span><span class="p">:</span>
                <span class="c1"># Find the token_label and token_value of the matching prefix</span>
                <span class="c1"># which is longest (with ties broken by the on_ties values).</span>
                <span class="n">label_and_value</span> <span class="o">=</span> <span class="n">token_table</span><span class="o">.</span><span class="n">get_next_token_label_and_value</span><span class="p">(</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">,</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">ERROR_MSG_TEXT_SNIPPET_SIZE</span><span class="p">)</span>
                <span class="n">token_label</span><span class="p">,</span> <span class="n">token_value</span> <span class="o">=</span> <span class="n">label_and_value</span>

                <span class="c1"># Remove matched prefix of the self.prog_unprocessed argument after</span>
                <span class="c1"># saving the matched prefix string.</span>
                <span class="n">original_matched_string</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                                        <span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">token_value</span><span class="p">)]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_value</span><span class="p">)</span>

                <span class="c1"># Look up the class to represent the winning_index.</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">token_subclass_for_label</span> <span class="o">=</span> <span class="n">token_table</span><span class="p">[</span><span class="n">token_label</span><span class="p">]</span>
                <span class="k">except</span> <span class="n">LexerException</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s2">&quot;Undefined key in token table for &quot;</span>
                                         <span class="s2">&quot;token_label &#39;</span><span class="si">{0}</span><span class="s2">&#39;.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">token_label</span><span class="p">))</span>

                <span class="c1"># Make an instance of the class to return (or at least to save</span>
                <span class="c1"># in the token&#39;s ignored_before if ignored).</span>
                <span class="n">token_instance</span> <span class="o">=</span> <span class="n">token_subclass_for_label</span><span class="p">(</span><span class="n">token_value</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_mod_function</span><span class="p">:</span>
                    <span class="n">token_instance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_mod_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_instance</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">all_token_count</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1"># Save the line and char counts for the beginning text of the</span>
                <span class="c1"># token with the token from the Lexer attributes.  Then update</span>
                <span class="c1"># the Lexer attributes.  Remember that the Lexer class versions</span>
                <span class="c1"># always refer to the beginning of the next token to be read</span>
                <span class="c1"># (into the buffer, not as the current token).  The versions</span>
                <span class="c1"># stored with the tokens themselves hold the beginning of text</span>
                <span class="c1"># when this routine scanned that token (including any ignored</span>
                <span class="c1"># text before it).</span>
                <span class="c1">#</span>
                <span class="c1"># Remember that we are looping and getting tokens which may turn</span>
                <span class="c1"># out to be ignored tokens (tested just below this block).</span>
                <span class="n">token_instance</span><span class="o">.</span><span class="n">line_and_char</span> <span class="o">=</span> <span class="p">(</span>
                                 <span class="bp">self</span><span class="o">.</span><span class="n">raw_linenumber</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">upcoming_raw_charnumber</span><span class="p">)</span>
                <span class="n">token_instance</span><span class="o">.</span><span class="n">char_index_in_program</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upcoming_raw_total_chars</span>
                <span class="n">num_newlines</span> <span class="o">=</span> <span class="n">token_value</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">raw_linenumber</span> <span class="o">+=</span> <span class="n">num_newlines</span>
                <span class="k">if</span> <span class="n">num_newlines</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">upcoming_raw_charnumber</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_value</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">first_after_newline</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="n">last_newline</span> <span class="o">=</span> <span class="n">token_value</span><span class="o">.</span><span class="n">rfind</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">upcoming_raw_charnumber</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="nb">len</span><span class="p">(</span><span class="n">token_value</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">last_newline</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">upcoming_raw_total_chars</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_value</span><span class="p">)</span>

                <span class="c1"># ------------------------------------------------------------------</span>
                <span class="c1"># Go to the top of the loop and get another if the token is ignored.</span>
                <span class="c1"># ------------------------------------------------------------------</span>
                <span class="k">if</span> <span class="n">token_label</span> <span class="ow">in</span> <span class="n">token_table</span><span class="o">.</span><span class="n">ignored_tokens</span><span class="p">():</span>
                    <span class="n">ignored_before_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_label</span><span class="p">)</span>
                    <span class="n">ignored_before_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_instance</span><span class="p">)</span>
                    <span class="k">continue</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">non_ignored_token_count</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># =======================================================================</span>
            <span class="c1"># === Return only end-tokens state ======================================</span>
            <span class="c1"># =======================================================================</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_generator_state</span> <span class="o">==</span> <span class="n">GenTokenState</span><span class="o">.</span><span class="n">end</span><span class="p">:</span>
                <span class="n">token_subclass_for_end</span> <span class="o">=</span> <span class="n">token_table</span><span class="p">[</span><span class="n">token_table</span><span class="o">.</span><span class="n">end_token_label</span><span class="p">]</span>
                <span class="n">token_instance</span> <span class="o">=</span> <span class="n">token_subclass_for_end</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_mod_function</span><span class="p">:</span>
                    <span class="n">token_instance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_mod_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_instance</span><span class="p">)</span>

                <span class="n">token_instance</span><span class="o">.</span><span class="n">line_and_char</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_linenumber</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">upcoming_raw_charnumber</span><span class="p">)</span>
                <span class="n">token_instance</span><span class="o">.</span><span class="n">char_index_in_program</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upcoming_raw_total_chars</span>

            <span class="c1"># Got a token to return.  Set some attributes and return it.</span>
            <span class="c1"># Note that the attributes below are not set on ignored tokens!</span>
            <span class="n">token_instance</span><span class="o">.</span><span class="n">original_matched_string</span> <span class="o">=</span> <span class="n">original_matched_string</span>
            <span class="n">token_instance</span><span class="o">.</span><span class="n">ignored_before</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">ignored_before_tokens</span><span class="p">)</span>
            <span class="n">token_instance</span><span class="o">.</span><span class="n">all_token_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_token_count</span>
            <span class="n">token_instance</span><span class="o">.</span><span class="n">non_ignored_token_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_ignored_token_count</span>
            <span class="n">token_instance</span><span class="o">.</span><span class="n">is_first</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_curr_token_is_first</span>
            <span class="n">token_instance</span><span class="o">.</span><span class="n">is_first_on_line</span> <span class="o">=</span> <span class="n">token_instance</span><span class="o">.</span><span class="n">is_first</span> <span class="ow">or</span> <span class="n">first_after_newline</span>

            <span class="k">return</span> <span class="n">token_instance</span></div>


<div class="viewcode-block" id="multi_funcall"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.multi_funcall">[docs]</a><span class="k">def</span> <span class="nf">multi_funcall</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">tuple_list</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A convenience function that takes a function (or method) and a list of tuples</span>
<span class="sd">    and calls `function` with the values in those tuple as arguments.</span>
<span class="sd">    Any unrecognized keyword arguments are passed on to the function `function`</span>
<span class="sd">    as keyword arguments.  If the `exception_to_raise` keyword argument is provided with</span>
<span class="sd">    an exception then that exception will be called whenever a `TypeError` results from</span>
<span class="sd">    the attempt to call `function` (defaulting to `LexerException`).&quot;&quot;&quot;</span>
    <span class="n">retval_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">exception_to_raise</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;exception_to_raise&quot;</span><span class="p">,</span> <span class="n">LexerException</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tuple_list</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">retval_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">function</span><span class="p">(</span><span class="o">*</span><span class="n">t</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">exception_to_raise</span><span class="p">(</span>
                    <span class="s2">&quot;Bad multi-definition of </span><span class="si">{0}</span><span class="s2">: Omitted required arguments or bad &quot;</span>
                    <span class="s2">&quot;keyword arguments passed in.  Error on this tuple:</span><span class="se">\n</span><span class="si">{1}</span><span class="se">\n</span><span class="s2">with &quot;</span>
                    <span class="s2">&quot;keyword arguments</span><span class="se">\n</span><span class="si">{2}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">function</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">))</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">retval_list</span><span class="p">)</span></div>

<div class="viewcode-block" id="return_first_exception"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.return_first_exception">[docs]</a><span class="k">def</span> <span class="nf">return_first_exception</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Go down the argument list and return the first object that is a</span>
<span class="sd">    subclass of the `Exception` class.  Arguments do not need to all be</span>
<span class="sd">    classes.  Returns `None` if all fail.  Used to allow an optional exception</span>
<span class="sd">    class to be passed to a function instead of true, with a default called</span>
<span class="sd">    if the passed-in value is not an exception.&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">is_subclass_of</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="ne">Exception</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">item</span>
    <span class="k">return</span> <span class="kc">None</span></div>

<span class="c1">#</span>
<span class="c1"># Exceptions</span>
<span class="c1">#</span>

<div class="viewcode-block" id="BufferIndexError"><a class="viewcode-back" href="../../typped.lexer.html#typped.lexer.BufferIndexError">[docs]</a><span class="k">class</span> <span class="nc">BufferIndexError</span><span class="p">(</span><span class="n">LexerException</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Raised on attempts to read past the beginning or the end of the buffer</span>
<span class="sd">    (such as in `peek` methods).&quot;&quot;&quot;</span>
    <span class="k">pass</span></div>


</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">Typped  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2016, Allen Barker.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.3.
    </div>
  </body>
</html>