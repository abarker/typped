<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>wff_language.regex_trie_dict_scanner &mdash; Skolem  documentation</title>
    
    <link rel="stylesheet" href="../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="top" title="Skolem  documentation" href="../../index.html" />
    <link rel="up" title="Module code" href="../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">Skolem  documentation</a> &raquo;</li>
          <li><a href="../index.html" accesskey="U">Module code</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <h1>Source code for wff_language.regex_trie_dict_scanner</h1><div class="highlight"><pre>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">RegexTrieDictScanner</span>
<span class="sd">----------------------</span>

<span class="sd">The RegexTrieDictScanner uses a RegexTrieDict for tokenizing a sequence of</span>
<span class="sd">elements.  This class essentially does the same thing that re.findall would do</span>
<span class="sd">in a traditional scanner design, except that it is easy to dynamically update</span>
<span class="sd">it (though it is less efficient at the static matching).</span>

<span class="sd">The elements (usually characters) are inserted one by one and tokens</span>
<span class="sd">are returned when they are recognized.  The key-sequences inserted into the</span>
<span class="sd">RegexTrieDict are by definition the tokens.  An arbitrary sequence can then be</span>
<span class="sd">tokenized by inserting it element by element into the TrieDict, using a special</span>
<span class="sd">method.  The shortest or longest matches can be found.  (Note that for</span>
<span class="sd">generality we refer to &quot;tokens&quot; and the &quot;elements&quot; that make up both the tokens</span>
<span class="sd">and the sequences to be tokenized.  In lexical analysis applications the tokens</span>
<span class="sd">are strings and the elements are characters.)</span>

<span class="sd">   tok = RegexTreeDictTokenizer(td)</span>

<span class="sd">   for i in &quot;eggbert&quot;:</span>
<span class="sd">      tok.insertSeqElem(i)</span>
<span class="sd">      tok.printTokenDeque()</span>
<span class="sd">   for i in &quot;eggber&quot;:</span>
<span class="sd">      tok.insertSeqElem(i)</span>
<span class="sd">      tok.printTokenDeque()</span>
<span class="sd">   tok.insertSeqElem(&quot;x&quot;)</span>

<span class="sd">The results of the tokenization are automatically place in a deque which is</span>
<span class="sd">stored with the RegexTreeDictTokenizer instance.  Users can manipulate this</span>
<span class="sd">deque in any way they want; it is only used for reporting tokens as they are</span>
<span class="sd">unambiguously detected (i.e., they are inserted when matched).  Note that it</span>
<span class="sd">may be necessary to call tok.assertEndOfSequence() in order for the tokenizer</span>
<span class="sd">to deal with situations that are currently ambiguous (as far as finding the</span>
<span class="sd">longest match).</span>

<span class="sd">   tok.assertEndOfSequence()</span>
<span class="sd">   tok.printTokenDeque()</span>
<span class="sd">   tok.clearDeque()</span>

<span class="sd">Key strings can be matched as tokens from a sequential character stream,</span>
<span class="sd">choosing either the longest or the shortest (first) match.  Finding the</span>
<span class="sd">shortest matches (assuming no regexes) is linear in the overall query string</span>
<span class="sd">length.  The time when finding the longest matches is still efficient in the</span>
<span class="sd">usual cases but is not linear in the query-lengths because recursion is used to</span>
<span class="sd">effectively back up when it becomes known that a recognized pattern is the</span>
<span class="sd">longest (in that part of the sequence).  But it must wait for a mismatch or the</span>
<span class="sd">end of the query string to know that a saved possible match was the longest.</span>

<span class="sd">Worst case, suppose we have these three keys:</span>
<span class="sd">   aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa</span>
<span class="sd">   a</span>
<span class="sd">   b</span>

<span class="sd">Now, suppose the input query-stream of characters is:</span>
<span class="sd">   aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaab</span>

<span class="sd">We save the first a as a possible match, and then we have to go all the way to</span>
<span class="sd">the final b to determine that the longer string is not a match (and the single</span>
<span class="sd">character is the longest match).  Then we go back and start the same thing over</span>
<span class="sd">from the second a, and so forth, getting a time which depends on the length of</span>
<span class="sd">the longest string stored and the prefix properties of the stored strings.</span>
<span class="sd">When the stored strings are relatively short relative to the query length and</span>
<span class="sd">are distributed in &quot;the usual ways&quot; this should not make much difference in</span>
<span class="sd">practice.</span>

<span class="sd">The tree can easily handle whitespace characters if whitespace characters are</span>
<span class="sd">never valid stored strings or substrings of stored strings.  We just get an</span>
<span class="sd">unrecognized string result on those characters (depending on how error handling</span>
<span class="sd">is configured, with fastRecover of not).  Alternately, and better, we can</span>
<span class="sd">insert one of each whitespace character into the tree and then just test and</span>
<span class="sd">ignore those matches.  Or we could just do a split on whitespace before feeding</span>
<span class="sd">data to the tree; that is probably best in most situations.</span>

<span class="sd">For queries of fixed keys which are either in the structure or not there is no</span>
<span class="sd">real advantage to using the tree algorithm (it will be slower since it uses a</span>
<span class="sd">standard dicts at each node for storing child nodes).  What the tree algorithm</span>
<span class="sd">can do well is recognize stored items (tokens) out of a continuous, sequential</span>
<span class="sd">stream of characters (either finding the first match or the longest), while</span>
<span class="sd">also allowing fast inserts and deletes of keys/tokens.</span>

<span class="sd">Using a standard hashed dict (or REs) for the same thing we would build up the</span>
<span class="sd">query string character by character and query the hash dict on the query string</span>
<span class="sd">each time a character is appended to it.  That is, generate the prefixes of the</span>
<span class="sd">input character string.  Then it would save possible matches, etc., and when a</span>
<span class="sd">match is recognized as the longest it would remove that prefix and restart,</span>
<span class="sd">just like the tree version below.  To find the longest match, however, we need</span>
<span class="sd">to know when a mismatch occurs or else go all the way to the end of the input</span>
<span class="sd">each time.  This would entail saving all the prefixes of all the keys (in</span>
<span class="sd">another dict, perhaps), or otherwise coming up with some scheme to detect when</span>
<span class="sd">no longer-match is possible (because the current query string is not a prefix</span>
<span class="sd">of any key).  This scheme would have to be able to be quickly updated on</span>
<span class="sd">inserts and deletes of keys.</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="c">#TODO: rewrite using the RegexTrieDict and Matcher classes</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span><span class="p">,</span> <span class="n">absolute_import</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">collections</span> <span class="c"># to use deque and MutableSequence abstract base class</span>
<span class="kn">import</span> <span class="nn">regex_trie_dict</span>


<div class="viewcode-block" id="TokenData"><a class="viewcode-back" href="../../wff_language.regex_trie_dict_scanner.html#wff_language.regex_trie_dict_scanner.TokenData">[docs]</a><span class="k">class</span> <span class="nc">TokenData</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This class is the basic container used by the RegexTrieDictScanner.  It</span>
<span class="sd">    holds a token (which may be an invalid token) and also some related data.</span>
<span class="sd">    The tokenDataDeque of the RegexTrieDictScanner (such as from getTokenDataDeque()</span>
<span class="sd">    calls) contains TokenData objects.</span>

<span class="sd">    A convention which is used in the language parsing application is that the</span>
<span class="sd">    self.data field contains a tuple of information where the first, 0th item in</span>
<span class="sd">    the tuple is a string giving the sort or type of language element, and the</span>
<span class="sd">    second or later elements contain data dependent of the sort of element.  The</span>
<span class="sd">    current module does not set any of these values, however, and so does have</span>
<span class="sd">    any need to know about or apply that convention.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">validToken</span><span class="p">,</span> <span class="n">tokenString</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">elemData</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validToken</span> <span class="o">=</span> <span class="n">validToken</span> <span class="c"># False if the &quot;token&quot; was not in the RegexTrieDict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenString</span> <span class="o">=</span> <span class="n">tokenString</span> <span class="c"># the string of the token which resulted in the match</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span> <span class="c"># some arbitrary piece of data stored as a key/data pair</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">elemData</span> <span class="o">=</span> <span class="n">elemData</span> <span class="c"># some arbitrary data stored on a query with each elem</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">&quot;TokenData(&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">validToken</span><span class="p">)</span><span class="o">+</span><span class="s">&quot;, &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenString</span><span class="p">)</span> <span class="o">+</span> \
            <span class="s">&quot;, &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="o">+</span><span class="s">&quot;, &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">elemData</span><span class="p">)</span><span class="o">+</span><span class="s">&quot;)&quot;</span>

    <span class="k">def</span> <span class="nf">__bool__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Allow for testing a TokenData object in conditionals, converting to bool.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">validToken</span>

</div>
<div class="viewcode-block" id="RegexTrieDictScanner"><a class="viewcode-back" href="../../wff_language.regex_trie_dict_scanner.html#wff_language.regex_trie_dict_scanner.RegexTrieDictScanner">[docs]</a><span class="k">class</span> <span class="nc">RegexTrieDictScanner</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This class uses the keys of a RegexTrieDict as tokens.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regexTrieDict</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;User must pass in a valid RegexTrieDict containing the tokens.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">td</span> <span class="o">=</span> <span class="n">regexTrieDict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
        <span class="k">return</span>

<div class="viewcode-block" id="RegexTrieDictScanner.clear"><a class="viewcode-back" href="../../wff_language.regex_trie_dict_scanner.html#wff_language.regex_trie_dict_scanner.RegexTrieDictScanner.clear">[docs]</a>    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Reset the tokenizer to its initial condition.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">matchLongest</span> <span class="o">=</span> <span class="bp">True</span> <span class="c"># whether to always look for longest match</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noInvalidTokensFound</span> <span class="o">=</span> <span class="bp">True</span> <span class="c"># whether unstored string found on curr query</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenDataDeque</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">()</span> <span class="c"># the deque of query matches</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">resetSeq</span><span class="p">()</span>
        <span class="k">return</span>
</div>
<div class="viewcode-block" id="RegexTrieDictScanner.resetSeq"><a class="viewcode-back" href="../../wff_language.regex_trie_dict_scanner.html#wff_language.regex_trie_dict_scanner.RegexTrieDictScanner.resetSeq">[docs]</a>    <span class="k">def</span> <span class="nf">resetSeq</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Reset the sequence from previous insertSeqElem calls, i.e.,</span>
<span class="sd">        start the next insertion back at the root node.  All of the saved possible</span>
<span class="sd">        token matches are deleted and not reported: this is a cold reset.  &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">currNode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">td</span><span class="o">.</span><span class="n">root</span> <span class="c"># the current node for current sequence elem</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tdInsertCount</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">td</span><span class="o">.</span><span class="n">insertCount</span> <span class="c"># to make sure Trie doesn&#39;t change</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tdDeleteCount</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">td</span><span class="o">.</span><span class="n">deleteCount</span> <span class="c"># to make sure Trie doesn&#39;t change</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">possibleMatch</span> <span class="o">=</span> <span class="bp">False</span> <span class="c"># True if a string matched which may not be longest</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">possibleToken</span> <span class="o">=</span> <span class="s">&quot;&quot;</span> <span class="c"># The string for the last possible match.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">possibleData</span> <span class="o">=</span> <span class="bp">None</span> <span class="c"># Data stored with possibleToken</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">possibleMiscList</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># List of misc data saved with each element.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">currToken</span> <span class="o">=</span> <span class="s">&quot;&quot;</span> <span class="c"># the concatenation of all elems so far in token being found</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">currMiscList</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># List of misc data saved with each element.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nonTreeMatchInProgress</span> <span class="o">=</span> <span class="bp">False</span> <span class="c"># true if a number match in progress</span>
        <span class="k">return</span>
</div>
<div class="viewcode-block" id="RegexTrieDictScanner.resetSeqAfterFlushing"><a class="viewcode-back" href="../../wff_language.regex_trie_dict_scanner.html#wff_language.regex_trie_dict_scanner.RegexTrieDictScanner.resetSeqAfterFlushing">[docs]</a>    <span class="k">def</span> <span class="nf">resetSeqAfterFlushing</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This flushes out the buffer of possible saved token matches before</span>
<span class="sd">        resetting the sequence of elements (back to start at the root).&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEndOfSeq</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resetSeq</span><span class="p">()</span> <span class="c"># done by self.assertEndOfSeq(), but do again to be safe</span>
        <span class="k">return</span>
</div>
<div class="viewcode-block" id="RegexTrieDictScanner.setMatchLongest"><a class="viewcode-back" href="../../wff_language.regex_trie_dict_scanner.html#wff_language.regex_trie_dict_scanner.RegexTrieDictScanner.setMatchLongest">[docs]</a>    <span class="k">def</span> <span class="nf">setMatchLongest</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">boolVal</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set True if longest matches should be found in insertSeqElem queries,</span>
<span class="sd">        False if shortest.  The default in initialization and after a clear()</span>
<span class="sd">        is True.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">matchLongest</span> <span class="o">=</span> <span class="n">boolVal</span>
        <span class="k">return</span>
</div>
<div class="viewcode-block" id="RegexTrieDictScanner.currentSeqIsValid"><a class="viewcode-back" href="../../wff_language.regex_trie_dict_scanner.html#wff_language.regex_trie_dict_scanner.RegexTrieDictScanner.currentSeqIsValid">[docs]</a>    <span class="k">def</span> <span class="nf">currentSeqIsValid</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return True if the current sequence being tokenized is still valid.</span>
<span class="sd">        Return False otherwise.  A sequence becomes invalid if there are any</span>
<span class="sd">        inserts or deletes in the underlying Trie.  This is just for informational</span>
<span class="sd">        purposes, since any attempt to insert an element in an invalid sequence</span>
<span class="sd">        will automatically call resetSeqAfterFlushing first and reset the sequence.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tdInsertCount</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">td</span><span class="o">.</span><span class="n">insertCount</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tdDeleteCount</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">td</span><span class="o">.</span><span class="n">deleteCount</span><span class="p">)</span>

    <span class="c">#</span>
    <span class="c"># Note that shortest match in insertSeqElem works easily, but what about</span>
    <span class="c"># finding the longest match?  We save the most recent possible match, and</span>
    <span class="c"># make it the actual match if a mismatch occurs after it.  How do</span>
    <span class="c"># we reset the tree after getting a mismatch?  We don&#39;t always learn</span>
    <span class="c"># immediately on the next elem if the earlier match is good or not.</span>
    <span class="c"># E.g., suppose &quot;egg&quot; and &quot;eggbert&quot; are stored and we query sequentially on</span>
    <span class="c"># the characters in &quot;eggberb&quot;.  We first find &quot;egg&quot; as a possible match.</span>
    <span class="c"># Then when we get to the final &quot;b&quot; we know that it is the longest match.</span>
    <span class="c"># At that point we remove the prefix &quot;egg&quot; from &quot;eggberb&quot; and re-query</span>
    <span class="c"># the characters in the string &quot;berb&quot;, starting again at the root of the</span>
    <span class="c"># tree.  Fortunately, the needed data is already being saved in</span>
    <span class="c"># currToken, which has been built up to &quot;eggberb&quot; after the final &quot;b&quot;</span>
    <span class="c"># has had insertSeqElem called on it.</span>
    <span class="c">#</span></div>
    <span class="n">digits</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="s">&quot;0&quot;</span><span class="p">,</span> <span class="s">&quot;1&quot;</span><span class="p">,</span> <span class="s">&quot;2&quot;</span><span class="p">,</span> <span class="s">&quot;3&quot;</span><span class="p">,</span> <span class="s">&quot;4&quot;</span><span class="p">,</span> <span class="s">&quot;5&quot;</span><span class="p">,</span> <span class="s">&quot;6&quot;</span><span class="p">,</span> <span class="s">&quot;7&quot;</span><span class="p">,</span> <span class="s">&quot;8&quot;</span><span class="p">,</span> <span class="s">&quot;9&quot;</span><span class="p">])</span>

<div class="viewcode-block" id="RegexTrieDictScanner.insertSeqElem"><a class="viewcode-back" href="../../wff_language.regex_trie_dict_scanner.html#wff_language.regex_trie_dict_scanner.RegexTrieDictScanner.insertSeqElem">[docs]</a>    <span class="k">def</span> <span class="nf">insertSeqElem</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">char</span><span class="p">,</span> <span class="n">miscData</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span> <span class="c"># TODO change to not depend on chars</span>
        <span class="sd">&quot;&quot;&quot; Insert the next element from the sequence being tokenized.  If</span>
<span class="sd">        inserting the element results in a match (including detecting an</span>
<span class="sd">        unrecognizable token) the matching token (or sequence of elements) is</span>
<span class="sd">        appended to the result deque, which the getTokenDataDeque method returns.</span>
<span class="sd">        This function returns True until some string has been recognized as not</span>
<span class="sd">        being stored in the tree, after which it returns False (this signals</span>
<span class="sd">        that some higher-level error-handling needs to be done).</span>

<span class="sd">        A future modification might allow multiple query instances,</span>
<span class="sd">        essentially a wrapper-class for pointers to nodes in the tree.</span>

<span class="sd">        The format of the tokenDataDeque is a deque of TokenData class instances.</span>

<span class="sd">        In lexical analysis:</span>

<span class="sd">        The optional miscData argument is miscellaneous data which is associated</span>
<span class="sd">        with the query chars (in particular, line numbers can be stored and</span>
<span class="sd">        &quot;passed up&quot; for better error reporting).</span>

<span class="sd">        Inserting the empty string &quot;&quot; is equivalent to asserting the end of the</span>
<span class="sd">        query string (and is how assertEndOfSeq() is implemented).&quot;&quot;&quot;</span>

        <span class="c"># Automatically reset after flushing if underlying Trie is no longer valid.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">currentSeqIsValid</span><span class="p">()</span> <span class="ow">and</span> <span class="n">char</span> <span class="o">!=</span> <span class="s">&quot;&quot;</span><span class="p">:</span> <span class="c"># TODO: don&#39;t use insert empty char for endOfSeq</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resetSeqAfterFlushing</span><span class="p">()</span>

        <span class="c"># Now handle any ordinary tree matches for the queryChar char.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">char</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">currNode</span><span class="o">.</span><span class="n">children</span><span class="p">:</span> <span class="c"># mismatch beyond current node</span>
            <span class="c"># empty string queryInserts always take this path from conditional above</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">possibleMatch</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenDataDeque</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TokenData</span><span class="p">(</span>
                                           <span class="bp">True</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">possibleToken</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">possibleData</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">possibleMiscList</span>
                                           <span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">possibleMatch</span> <span class="o">=</span> <span class="bp">False</span>
                <span class="c"># remove recognized possibleMatch prefix from currToken</span>
                <span class="c"># note that suffix is saved in a local var for recursion</span>
                <span class="n">suffix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">currToken</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">possibleToken</span><span class="p">):]</span>
                <span class="n">suffix</span> <span class="o">+=</span> <span class="n">char</span>
                <span class="n">suffixMisc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">currMiscList</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">possibleToken</span><span class="p">):]</span>
                <span class="k">if</span> <span class="n">char</span> <span class="o">!=</span> <span class="s">&quot;&quot;</span><span class="p">:</span> <span class="n">suffixMisc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">miscData</span><span class="p">)</span>
                <span class="c"># reset query and re-query each char of the suffix string</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">resetSeq</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">suffix</span><span class="p">)):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">insertSeqElem</span><span class="p">(</span><span class="n">suffix</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">suffixMisc</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">noInvalidTokensFound</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c"># Char doesn&#39;t match a child, no saved match, but currToken</span>
                <span class="c"># matched a prefix of something up to here.  So there is</span>
                <span class="c"># some error in the currToken.  There are various ways to</span>
                <span class="c"># handle error recovery.</span>
                <span class="c">#</span>
                <span class="n">fastRecover</span> <span class="o">=</span> <span class="bp">True</span> <span class="c"># this could be a settable class variable</span>
                <span class="c">#</span>
                <span class="c"># To fastRecover, ditch all of the currToken rather than</span>
                <span class="c"># trying to reinsert various parts to do &quot;maximum recovery.&quot;</span>
                <span class="c"># Reset and try re-querying the fail-char if currToken had</span>
                <span class="c"># nonzero length.  Slower, we can just report the first char</span>
                <span class="c"># of currToken as a fail, and reinsert all else + char.</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">currToken</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">noInvalidTokensFound</span> <span class="o">=</span> <span class="bp">False</span> <span class="c"># set error return flag</span>
                    <span class="k">if</span> <span class="n">fastRecover</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">tokenDataDeque</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TokenData</span><span class="p">(</span>
                                                   <span class="bp">False</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">currToken</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">currMiscList</span><span class="p">))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">tokenDataDeque</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TokenData</span><span class="p">(</span>
                                                   <span class="bp">False</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">currToken</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">currMiscList</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
                    <span class="n">savedCurrToken</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">currToken</span>
                    <span class="n">savedCurrMiscList</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">currMiscList</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">resetSeq</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">fastRecover</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">char</span> <span class="o">!=</span> <span class="s">&quot;&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">insertSeqElem</span><span class="p">(</span><span class="n">char</span><span class="p">,</span> <span class="n">miscData</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">savedCurrToken</span> <span class="o">=</span> <span class="n">savedCurrToken</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">char</span>
                        <span class="n">savedCurrMiscList</span> <span class="o">=</span> <span class="n">savedCurrMiscList</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
                        <span class="k">if</span> <span class="n">char</span> <span class="o">!=</span> <span class="s">&quot;&quot;</span><span class="p">:</span>
                            <span class="n">savedCurrMiscList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">miscData</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">insertSeqElem</span><span class="p">(</span><span class="n">savedCurrToken</span><span class="p">,</span> <span class="n">savedCurrMiscList</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span> <span class="c"># only the current char doesn&#39;t match, at root</span>
                    <span class="k">if</span> <span class="n">char</span> <span class="o">!=</span> <span class="s">&quot;&quot;</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">noInvalidTokensFound</span> <span class="o">=</span> <span class="bp">False</span> <span class="c"># set error return flag</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">tokenDataDeque</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="n">TokenData</span><span class="p">(</span><span class="bp">False</span><span class="p">,</span> <span class="n">char</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="p">[</span><span class="n">miscData</span><span class="p">]))</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">resetSeq</span><span class="p">()</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">noInvalidTokensFound</span>

        <span class="c"># At this point we know there is another node below the current one.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">currToken</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">currToken</span> <span class="o">+</span> <span class="n">char</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">currMiscList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">miscData</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">currNode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">currNode</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="n">char</span><span class="p">]</span> <span class="c"># move currNode down tree</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">currNode</span><span class="o">.</span><span class="n">isLastElemOfKey</span><span class="p">:</span>
            <span class="c"># to match longest we must wait before concluding, unless we are at a leaf</span>
            <span class="n">numChildren</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">currNode</span><span class="o">.</span><span class="n">children</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">matchLongest</span> <span class="ow">and</span> <span class="n">numChildren</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c"># matchLongest and not at a leaf</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">possibleMatch</span> <span class="o">=</span> <span class="bp">True</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">possibleToken</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">currToken</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">possibleData</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">currNode</span><span class="o">.</span><span class="n">data</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">possibleMiscList</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">currMiscList</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c"># match shortest or else at a leaf</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenDataDeque</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TokenData</span><span class="p">(</span>
                                           <span class="bp">True</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">currToken</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">currNode</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">currMiscList</span>
                                           <span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">resetSeq</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">noInvalidTokensFound</span>
</div>
<div class="viewcode-block" id="RegexTrieDictScanner.getTokenDataDeque"><a class="viewcode-back" href="../../wff_language.regex_trie_dict_scanner.html#wff_language.regex_trie_dict_scanner.RegexTrieDictScanner.getTokenDataDeque">[docs]</a>    <span class="k">def</span> <span class="nf">getTokenDataDeque</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the deque of matches generated by insertSeqElem calls.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenDataDeque</span>
</div>
<div class="viewcode-block" id="RegexTrieDictScanner.clearTokenDataDeque"><a class="viewcode-back" href="../../wff_language.regex_trie_dict_scanner.html#wff_language.regex_trie_dict_scanner.RegexTrieDictScanner.clearTokenDataDeque">[docs]</a>    <span class="k">def</span> <span class="nf">clearTokenDataDeque</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets the current deque of matches empty.  This may be useful in an</span>
<span class="sd">        algorithm, or to free memory in a long sequence.  Does not alter anything</span>
<span class="sd">        else, including the current query and any saved possible-match value.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenDataDeque</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</div>
<div class="viewcode-block" id="RegexTrieDictScanner.assertEndOfSeq"><a class="viewcode-back" href="../../wff_language.regex_trie_dict_scanner.html#wff_language.regex_trie_dict_scanner.RegexTrieDictScanner.assertEndOfSeq">[docs]</a>    <span class="k">def</span> <span class="nf">assertEndOfSeq</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Asserts that there are no more elements in the current sequence.</span>
<span class="sd">        Will empty out the buffer of elements and of possible matches.&quot;&quot;&quot;</span>
        <span class="c"># TODO do we still want null string, or special end token?</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">insertSeqElem</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">)</span>
</div>
<div class="viewcode-block" id="RegexTrieDictScanner.printTokenDeque"><a class="viewcode-back" href="../../wff_language.regex_trie_dict_scanner.html#wff_language.regex_trie_dict_scanner.RegexTrieDictScanner.printTokenDeque">[docs]</a>    <span class="k">def</span> <span class="nf">printTokenDeque</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Debugging routine, print out all the strings in tokenDataDeque.&quot;&quot;&quot;</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&quot;TokenDeque[&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenDataDeque</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenDataDeque</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenDataDeque</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">tokenString</span><span class="o">+</span><span class="s">&quot;,&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenDataDeque</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">tokenString</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&quot;]&quot;</span><span class="p">)</span>


<span class="c">#</span>
<span class="c"># Run test cases below when invoked as a script.</span>
<span class="c">#</span>

</div></div>
<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&quot;__main__&quot;</span><span class="p">:</span>

    <span class="kn">import</span> <span class="nn">pytest_helper</span>
    <span class="n">pytest_helper</span><span class="o">.</span><span class="n">script_run</span><span class="p">(</span><span class="s">&quot;test/test_regex_trie_dict_scanner.py&quot;</span><span class="p">,</span> <span class="n">pytest_args</span><span class="o">=</span><span class="s">&quot;-v&quot;</span><span class="p">)</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">Skolem  documentation</a> &raquo;</li>
          <li><a href="../index.html" >Module code</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2015, Allen Barker.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
    </div>
  </body>
</html>