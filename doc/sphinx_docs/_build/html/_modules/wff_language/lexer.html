<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>wff_language.lexer &mdash; Skolem  documentation</title>
    
    <link rel="stylesheet" href="../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="top" title="Skolem  documentation" href="../../index.html" />
    <link rel="up" title="Module code" href="../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">Skolem  documentation</a> &raquo;</li>
          <li><a href="../index.html" accesskey="U">Module code</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <h1>Source code for wff_language.lexer</h1><div class="highlight"><pre>
<span class="c"># -*- coding: utf-8 -*-</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="sd">A general lexer/scanner module.</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span><span class="p">,</span> <span class="n">absolute_import</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">types</span>
<span class="kn">import</span> <span class="nn">collections</span>

<span class="c">#</span>
<span class="c"># TokenNode</span>
<span class="c">#</span>

<div class="viewcode-block" id="TokenNode"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenNode">[docs]</a><span class="k">class</span> <span class="nc">TokenNode</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The base class for token objects.&quot;&quot;&quot;</span>
    <span class="n">token_label</span> <span class="o">=</span> <span class="bp">None</span> <span class="c"># A label for subclasses representing kinds of tokens.</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the TokenNode.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">children</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># Args to functions are their children in parse tree.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="o">=</span> <span class="bp">None</span> <span class="c"># The parent in a tree of nodes.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignored_before_tokens</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># Values ignored by lexer just before.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span> <span class="o">=</span> <span class="bp">None</span> <span class="c"># A method to evaluate some nodes, added dynamically.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_type</span> <span class="o">=</span> <span class="bp">None</span> <span class="c"># The type of the node&#39;s value, after processing.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allowed_types</span> <span class="o">=</span> <span class="bp">None</span> <span class="c"># Set in recursion to ensure return type matches.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="bp">None</span> <span class="c"># The actual parsed text string for the token.</span>

<div class="viewcode-block" id="TokenNode.original_text"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenNode.original_text">[docs]</a>    <span class="k">def</span> <span class="nf">original_text</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the original text that was read in lexing the token, including</span>
<span class="sd">        any ignored text.&quot;&quot;&quot;</span>
        <span class="c">#ignored_strings = [ s.value for s in self.ignored_before_tokens ]</span>
        <span class="c">#joined = &quot;&quot;.join(ignored_strings) + self.value</span>
        <span class="c">#assert joined == self.original_matched_string</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_matched_string</span>
</div>
<div class="viewcode-block" id="TokenNode.ignored_before"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenNode.ignored_before">[docs]</a>    <span class="k">def</span> <span class="nf">ignored_before</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the list of tokens which were ignored just before this token.</span>
<span class="sd">        This can be used, for example, to make sure that there is whitespace</span>
<span class="sd">        between two tokens which require whitespace between them.  It can also</span>
<span class="sd">        be used to find the level of indentation before a token.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignored_before_tokens</span>
</div>
<div class="viewcode-block" id="TokenNode.ignored_before_labels"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenNode.ignored_before_labels">[docs]</a>    <span class="k">def</span> <span class="nf">ignored_before_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the list of token labels of tokens which were ignored just</span>
<span class="sd">        before this token.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">token_label</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignored_before_tokens</span><span class="p">]</span>
</div>
<div class="viewcode-block" id="TokenNode.append_children"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenNode.append_children">[docs]</a>    <span class="k">def</span> <span class="nf">append_children</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">token_nodes</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Append all the arguments as children, also setting their parent to self.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">token_nodes</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
            <span class="n">t</span><span class="o">.</span><span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span>
</div>
<div class="viewcode-block" id="TokenNode.convert_to_AST"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenNode.convert_to_AST">[docs]</a>    <span class="k">def</span> <span class="nf">convert_to_AST</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">convert_TokenNode_to_AST_node_fun</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call this on the root node.  Converts the token tree to an abstract</span>
<span class="sd">        syntax tree.  This basically converts the nodes one-to-one to a more</span>
<span class="sd">        convenient type of node for the AST of a given application.  The</span>
<span class="sd">        function `convert_TokenNode_to_AST_node_fun` should take one argument,</span>
<span class="sd">        a `TokenNode` instance, and return an AST node instance for the</span>
<span class="sd">        corresponding AST node.  Note that `ast_label` is an attribute of all</span>
<span class="sd">        `TokenNode` instances in the final tree.  Any other attributes can be</span>
<span class="sd">        copied over.  The AST nodes are only assumed to have an append_children</span>
<span class="sd">        method which appends a child AST node.&quot;&quot;&quot;</span>
        <span class="n">ast_node</span> <span class="o">=</span> <span class="n">convert_TokenNode_to_AST_node_fun</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span> 
            <span class="n">ast_node</span><span class="o">.</span><span class="n">append_children</span><span class="p">(</span>
                    <span class="n">child</span><span class="o">.</span><span class="n">convert_to_AST</span><span class="p">(</span><span class="n">convert_TokenNode_to_AST_node_fun</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ast_node</span>

    <span class="c">#</span>
    <span class="c"># Various representations.</span>
    <span class="c">#</span>
</div>
<div class="viewcode-block" id="TokenNode.value_repr"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenNode.value_repr">[docs]</a>    <span class="k">def</span> <span class="nf">value_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">)</span></div>
<div class="viewcode-block" id="TokenNode.label_repr"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenNode.label_repr">[docs]</a>    <span class="k">def</span> <span class="nf">label_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_label</span><span class="p">)</span></div>
<div class="viewcode-block" id="TokenNode.summary_repr"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenNode.summary_repr">[docs]</a>    <span class="k">def</span> <span class="nf">summary_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">&quot;&lt;&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_label</span><span class="p">)</span> <span class="o">+</span> <span class="s">&quot;,&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">)</span> <span class="o">+</span> <span class="s">&quot;&gt;&quot;</span></div>
<div class="viewcode-block" id="TokenNode.tree_repr"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenNode.tree_repr">[docs]</a>    <span class="k">def</span> <span class="nf">tree_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">):</span>
        <span class="n">string</span> <span class="o">=</span> <span class="n">indent</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_repr</span><span class="p">()</span> <span class="o">+</span> <span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="n">string</span> <span class="o">+=</span> <span class="n">c</span><span class="o">.</span><span class="n">tree_repr</span><span class="p">(</span><span class="n">indent</span><span class="o">=</span><span class="n">indent</span><span class="o">+</span><span class="s">&quot; &quot;</span><span class="o">*</span><span class="mi">4</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">string</span></div>
<div class="viewcode-block" id="TokenNode.string_repr"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenNode.string_repr">[docs]</a>    <span class="k">def</span> <span class="nf">string_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">only_vals</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">only_labels</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="n">string</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_repr</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">only_vals</span><span class="p">:</span> <span class="n">string</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_repr</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">only_labels</span><span class="p">:</span> <span class="n">string</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_repr</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="n">string</span> <span class="o">+=</span> <span class="s">&quot;(&quot;</span>
            <span class="n">string</span> <span class="o">+=</span> <span class="s">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">string_repr</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">)</span>
            <span class="n">string</span> <span class="o">+=</span> <span class="s">&quot;)&quot;</span>
        <span class="k">return</span> <span class="n">string</span></div>
<div class="viewcode-block" id="TokenNode.old_repr"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenNode.old_repr">[docs]</a>    <span class="k">def</span> <span class="nf">old_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This old representation is kept because it is used in some tests.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_label</span> <span class="o">==</span> <span class="s">&quot;number&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="s">&quot;[literal {0}]&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_label</span> <span class="o">==</span> <span class="s">&quot;lpar&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span> <span class="k">return</span> <span class="s">&quot;[lpar {0} rpar]&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">old_repr</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span> <span class="k">return</span> <span class="s">&quot;[literal lpar]&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">str_val</span> <span class="o">=</span> <span class="s">&quot;[&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span> <span class="n">str_val</span> <span class="o">+=</span> <span class="s">&quot; &quot;</span> <span class="o">+</span> <span class="n">a</span><span class="o">.</span><span class="n">old_repr</span><span class="p">()</span>
            <span class="n">str_val</span> <span class="o">+=</span> <span class="s">&quot;]&quot;</span>
            <span class="k">return</span> <span class="n">str_val</span></div>
    <span class="n">__repr__</span> <span class="o">=</span> <span class="n">string_repr</span>

</div>
<div class="viewcode-block" id="create_token_subclass"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.create_token_subclass">[docs]</a><span class="k">def</span> <span class="nf">create_token_subclass</span><span class="p">():</span>

    <span class="sd">&quot;&quot;&quot;Create and return a new token subclass representing tokens with label</span>
<span class="sd">    `token_label`.  This is called from the `create_token_subclass` method  of</span>
<span class="sd">    `TokenSubclassSymbolTable` when it needs to create a new one to start with.</span>
<span class="sd">    This function should not be called directly, since attributes (like the</span>
<span class="sd">    token label and a new subclass name) need to be added to the generated</span>
<span class="sd">    subclass.</span>
<span class="sd">    </span>
<span class="sd">    This function is the default argument to the `token_subclassing_fun`</span>
<span class="sd">    keyword argument of the initializer for `TokenSubclassSymbolTable`.  Users</span>
<span class="sd">    can define their own such function in order to add methods particular to</span>
<span class="sd">    their application (the PrattParser class does this).</span>

<span class="sd">    Using a separate subclass for each token label allows for attributes and</span>
<span class="sd">    methods specific to a kind of token to be pasted onto the class itself</span>
<span class="sd">    without conflicts.  For example, the PrattParser subclass adds nud and led</span>
<span class="sd">    methods which are specific to a given token label.&quot;&quot;&quot;</span>

    <span class="k">class</span> <span class="nc">TokenSubclass</span><span class="p">(</span><span class="n">TokenNode</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">TokenSubclass</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span> <span class="c"># Call base class __init__.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">value</span> <span class="c"># Set by Lexer token generator for instances.</span>

    <span class="k">return</span> <span class="n">TokenSubclass</span>

<span class="c">#</span>
<span class="c"># Token subclass symbol table</span>
<span class="c">#</span>
</div>
<div class="viewcode-block" id="TokenSubclassSymbolTable"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenSubclassSymbolTable">[docs]</a><span class="k">class</span> <span class="nc">TokenSubclassSymbolTable</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This is mainly used by the `Lexer` class.  A symbol table holding</span>
<span class="sd">    subclasses of the `TokenNode` class for each token label defined in a `Lexer`</span>
<span class="sd">    instance.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_subclassing_fun</span><span class="o">=</span><span class="n">create_token_subclass</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the symbol table.  The parameter `token_subclassing_fun`</span>
<span class="sd">        can be passed a function to be used to generate token subclasses,</span>
<span class="sd">        taking a token label as an argument.  The default is</span>
<span class="sd">        `create_token_subclass`.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_subclassing_fun</span> <span class="o">=</span> <span class="n">token_subclassing_fun</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_subclass_dict</span> <span class="o">=</span> <span class="p">{}</span>

<div class="viewcode-block" id="TokenSubclassSymbolTable.has_key"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenSubclassSymbolTable.has_key">[docs]</a>    <span class="k">def</span> <span class="nf">has_key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Test whether a token subclass for `token_label` has been stored.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">token_label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_subclass_dict</span>
</div>
<div class="viewcode-block" id="TokenSubclassSymbolTable.get_token_subclass"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenSubclassSymbolTable.get_token_subclass">[docs]</a>    <span class="k">def</span> <span class="nf">get_token_subclass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Look up the subclasses of base class `TokenNode` corresponding to</span>
<span class="sd">        `token_label` in the symbol table and return it.  Raises a</span>
<span class="sd">        `LexerException` if no subclass is found for the token label.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">token_label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_subclass_dict</span><span class="p">:</span>
            <span class="n">TokenSubclass</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_subclass_dict</span><span class="p">[</span><span class="n">token_label</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span> <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s">&quot;No token with label {0} is in the symbol table.&quot;</span>
                                   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">token_label</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">TokenSubclass</span>
</div>
<div class="viewcode-block" id="TokenSubclassSymbolTable.create_token_subclass"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenSubclassSymbolTable.create_token_subclass">[docs]</a>    <span class="k">def</span> <span class="nf">create_token_subclass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">,</span> <span class="n">store_in_dict</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a subclass for tokens with label `token_label` and store it</span>
<span class="sd">        in the symbol table.  Return the new subclass.  Raises a `LexerException`</span>
<span class="sd">        if a subclass for `token_label` has already been created.  If</span>
<span class="sd">        `store_in_dict` is `False` then the token is not stored.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">token_label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_subclass_dict</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s">&quot;In create_token_subclass, already created the&quot;</span>
                    <span class="s">&quot; token subclass for token_label &#39;{0}&#39;.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">token_label</span><span class="p">))</span>
        <span class="c"># Create a new token subclass for token_label and add some attributes.</span>
        <span class="n">TokenSubclass</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_subclassing_fun</span><span class="p">()</span>
        <span class="n">TokenSubclass</span><span class="o">.</span><span class="n">token_label</span> <span class="o">=</span> <span class="n">token_label</span>
        <span class="n">TokenSubclass</span><span class="o">.</span><span class="n">__name__</span> <span class="o">=</span> <span class="s">&quot;token_subclass-&quot;</span> <span class="o">+</span> <span class="n">token_label</span> <span class="c"># For debugging.</span>
        <span class="c"># Store the newly-created subclass in the token_dict.</span>
        <span class="k">if</span> <span class="n">store_in_dict</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_subclass_dict</span><span class="p">[</span><span class="n">token_label</span><span class="p">]</span> <span class="o">=</span> <span class="n">TokenSubclass</span>
        <span class="k">return</span> <span class="n">TokenSubclass</span>
</div>
<div class="viewcode-block" id="TokenSubclassSymbolTable.undefine_token_subclass"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.TokenSubclassSymbolTable.undefine_token_subclass">[docs]</a>    <span class="k">def</span> <span class="nf">undefine_token_subclass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Un-define the token with label token_label.  The `TokenNode` subclass</span>
<span class="sd">        previously associated with that label is removed from the dictionary.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span> <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_subclass_dict</span><span class="p">[</span><span class="n">token_label</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span> <span class="k">return</span> <span class="c"># Not saved in dict, ignore.</span>
    
<span class="c">#</span>
<span class="c"># Lexer</span>
<span class="c">#</span>
</div></div>
<div class="viewcode-block" id="GenTokenState"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.GenTokenState">[docs]</a><span class="k">class</span> <span class="nc">GenTokenState</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;The state of the token_generator program execution.&quot;&quot;&quot;</span>
    <span class="n">ordinary</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">end</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">uninitialized</span> <span class="o">=</span> <span class="mi">3</span>
</div>
<div class="viewcode-block" id="Lexer"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer">[docs]</a><span class="k">class</span> <span class="nc">Lexer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Scans the program and returns the tokens, represented by instances of</span>
<span class="sd">    `TokenNode` subclass instances. There is one subclass for each kind of</span>
<span class="sd">    token, i.e., for each token label.  These subclasses themselves are assumed</span>
<span class="sd">    to have been created before any scanning operation which can return an</span>
<span class="sd">    instance, via the `define_token` method. </span>
<span class="sd">    </span>
<span class="sd">    Token strings are assumed to have both a begin and an end token, defined</span>
<span class="sd">    via the `define_begin_and_end_tokens` method.  These token types act as</span>
<span class="sd">    sentinels at the beginning and end of the token stream.  Exactly one end</span>
<span class="sd">    token will be returned by `next`; any further calls to `next` raise</span>
<span class="sd">    `StopIteration`.</span>
<span class="sd">    </span>
<span class="sd">    The scanning is independent of the order in which tokens are defined.  The</span>
<span class="sd">    longest match over all token patterns will always be the one selected.  In</span>
<span class="sd">    case of ties the `on_ties` value (passed to `define_token`) is used to</span>
<span class="sd">    break it.  If that fails a `LexerException` is raised.</span>
<span class="sd">    </span>
<span class="sd">    If no symbol table is passed into `__init__` the `Lexer` will create its</span>
<span class="sd">    own empty one.&quot;&quot;&quot;</span>

    <span class="n">ERROR_MSG_TEXT_SNIPPET_SIZE</span> <span class="o">=</span> <span class="mi">40</span> <span class="c"># Number of characters to show for context.</span>

    <span class="c">#</span>
    <span class="c"># Initialization methods</span>
    <span class="c">#</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">symbol_table</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">num_lookahead_tokens</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                 <span class="n">max_go_back_tokens</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the Lexer.  Optional arguments set the</span>
<span class="sd">        `TokenSubclassSymbolTable` to be used (default creates a new one), the</span>
<span class="sd">        number of lookahead tokens (default is two), or the maximum number of</span>
<span class="sd">        tokens that the `go_back` method can accept (default is unlimited).&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">symbol_table</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">symbol_table</span> <span class="o">=</span> <span class="n">TokenSubclassSymbolTable</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">symbol_table</span> <span class="o">=</span> <span class="n">symbol_table</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore_tokens</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

        <span class="c"># These three lists below are kept in the same order so the same index</span>
        <span class="c"># will correctly index into them.  There is one entry for each token,</span>
        <span class="c"># in the same order as they were defined.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_labels</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># The list of token_labels.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compiled_regexes</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># The compiled regexes for recognizing tokens.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">on_ties</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># List of int values for breaking equal-length match ties.</span>

        <span class="c"># Consider integrating the lookahead tokens and the previous tokens</span>
        <span class="c"># into a single buffer.  Then the lookahead is just a slice of that</span>
        <span class="c"># buffer.  This allows easy pushback operations, at least.  Obviously</span>
        <span class="c"># next() would have to be modified to know when to use generate_token</span>
        <span class="c"># or not.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">NUM_LOOKAHEAD_TOKENS</span> <span class="o">=</span> <span class="n">num_lookahead_tokens</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">MAX_TOKEN_BUFFER_SIZE</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">NUM_LOOKAHEAD_TOKENS</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">MAX_TOKEN_BUFFER_SIZE</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">MAX_GO_BACK_TOKENS</span> <span class="o">=</span> <span class="n">max_go_back_tokens</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">MAX_GO_BACK_TOKENS</span><span class="p">:</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">PREV_TOKEN_BUF_SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">MAX_GO_BACK_TOKENS</span> 
                                        <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">NUM_LOOKAHEAD_TOKENS</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">PREV_TOKEN_BUF_SIZE</span> <span class="o">=</span> <span class="bp">None</span> <span class="c"># None gives unlimited number.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">previous_tokens</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">PREV_TOKEN_BUF_SIZE</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reset_linenumber</span> <span class="o">=</span> <span class="bp">True</span> <span class="c"># Reset linenumber on each set_text call.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linenumber</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_charnumber</span> <span class="o">=</span> <span class="bp">True</span> <span class="c"># Reset charnumber on each set_text call.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">charnumber</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">token_generator_state</span> <span class="o">=</span> <span class="n">GenTokenState</span><span class="o">.</span><span class="n">uninitialized</span>
        <span class="k">return</span>

<div class="viewcode-block" id="Lexer.set_text"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.set_text">[docs]</a>    <span class="k">def</span> <span class="nf">set_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">program</span><span class="p">):</span>
        <span class="c"># TODO: redefine to take a TextStream.  Be sure to also pass back position</span>
        <span class="c"># info with the returned text so that tokens have have their line/position</span>
        <span class="c"># of origin pasted onto them..... or at least keep track in generating</span>
        <span class="c"># tokens.</span>
        <span class="sd">&quot;&quot;&quot;Users should call this method to pass in the program text (or other</span>
<span class="sd">        text) which is to be lexically scanned.  The parameter `program` should</span>
<span class="sd">        be a string.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">begin_token_label</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_token_label</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s">&quot;Begin and end tokens must be defined by calling&quot;</span>
                    <span class="s">&quot; define_begin_and_end_tokens before set_text can be called.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">already_returned_end_token</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_curr_token_is_first</span> <span class="o">=</span> <span class="bp">False</span> <span class="c"># Is curr token first non-ignored in text?</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_returned_first_token</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">previous_tokens</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignored_before_curr</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># Tokens ignored just before current one.</span>

        <span class="c"># Reset line, character, and token counts.  All counts include the buffer.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_linenumber</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">linenumber</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_charnumber</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">charnumber</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_token_count</span> <span class="o">=</span> <span class="mi">0</span> <span class="c"># Count all actual tokens (not begin and end).</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">non_ignored_token_count</span> <span class="o">=</span> <span class="mi">0</span> <span class="c"># Count non-ignored actual tokens.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">program</span> <span class="o">=</span> <span class="n">program</span> <span class="c"># The program text currently being scanned/lexed.</span>
        <span class="c"># The prog_unprocessed list holds slice indices for the unprocessed part</span>
        <span class="c"># of the program text.  The go_back routine can modify this.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="p">)]</span> <span class="c"># The unprocessed slice.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_generator_state</span> <span class="o">=</span> <span class="n">GenTokenState</span><span class="o">.</span><span class="n">ordinary</span>

        <span class="c"># Set up the token buffer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_token_buffer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c"># Last token returned; begin token here.</span>
</div>
    <span class="k">def</span> <span class="nf">_initialize_token_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;A utility routine to initialize (fill) the token buffer.  The</span>
<span class="sd">        `token_buffer[0]` slot is the current token.  The current token will be</span>
<span class="sd">        set to the begin token after this routine runs (since no tokens have</span>
<span class="sd">        yet been read with `next`).  Any tokens in the buffer past the first</span>
<span class="sd">        end token are also set to end tokens.  The size of the token buffer is</span>
<span class="sd">        `self.NUM_LOOKAHEAD_TOKENS` plus one for the current token.  For</span>
<span class="sd">        two-token lookahead the buffer deque has the form:</span>
<span class="sd">            [&lt;current_token&gt;, &lt;peek1&gt;, &lt;peek2&gt;]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c"># Put a begin token sentinel in self.previous_tokens if it is empty.</span>
        <span class="n">begin_tok</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">begin_token_subclass</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">previous_tokens</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">previous_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">begin_tok</span><span class="p">)</span>

        <span class="c"># Set up the buffer.</span>
        <span class="n">tb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">begin_tok</span><span class="p">)</span> <span class="c"># This will be popped off on first next().</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">NUM_LOOKAHEAD_TOKENS</span><span class="p">):</span> <span class="c"># Fill with lookaheads.</span>
            <span class="n">new_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_generator</span><span class="p">()</span> <span class="c"># Will generate all end tokens at end.</span>
            <span class="n">tb</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_token</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">tb</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">token_label</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">begin_token_label</span> <span class="c"># debug, remove</span>

    <span class="c">#</span>
    <span class="c"># Next and peek related methods</span>
    <span class="c">#</span>

<div class="viewcode-block" id="Lexer.next"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.next">[docs]</a>    <span class="k">def</span> <span class="nf">next</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the next token, consuming from the token stream.  Also sets</span>
<span class="sd">        `self.token` to the return value.  Returns one end token and raises</span>
<span class="sd">        `StopIteration` on a `next` after that end token.  If `num` is greater</span>
<span class="sd">        than one a list of the tokens is returned (this list is cut short if</span>
<span class="sd">        the first end token is encountered, and so will never generate</span>
<span class="sd">        `StopIteration`).  This method adds buffering on top of the lower-level</span>
<span class="sd">        routine `token_generator`.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">already_returned_end_token</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">StopIteration</span>

        <span class="c"># Handle num &gt; 1 case with recursion.</span>
        <span class="k">if</span> <span class="n">num</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">ret_list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_end_token</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="p">):</span>
                    <span class="n">ret_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">next</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span> <span class="k">break</span>
            <span class="k">return</span> <span class="n">ret_list</span>

        <span class="c"># Handle ordinary case.</span>
        <span class="n">tb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">popleft</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">tb</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">token_label</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_token_label</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">already_returned_end_token</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_generator</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token</span> <span class="o">=</span> <span class="n">tb</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span></div>
    <span class="n">__next__</span> <span class="o">=</span> <span class="nb">next</span> <span class="c"># For Python 3.</span>
    
    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">return</span> <span class="bp">self</span> <span class="c"># Class provides its own __next__ method.</span>

<div class="viewcode-block" id="Lexer.peek"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.peek">[docs]</a>    <span class="k">def</span> <span class="nf">peek</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_toks</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Peek ahead in the token stream without consuming any tokens.  Note</span>
<span class="sd">        that the argument is the actual number of tokens ahead to peek.  I.e.,</span>
<span class="sd">        the indexing starts at 1. (You can consider 0 to mean to peek at</span>
<span class="sd">        the current token, and that also works.)  Peeking beyond the end</span>
<span class="sd">        of the buffer raises `BufferIndexError`, a subclass of `IndexError`.</span>
<span class="sd">        A peek within the buffer size is always valid, and returns an end</span>
<span class="sd">        token for all peeks from the first end token and beyond.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span> <span class="n">retval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">[</span><span class="n">num_toks</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span> <span class="k">raise</span> <span class="n">BufferIndexError</span>
        <span class="k">return</span> <span class="n">retval</span>
</div>
<div class="viewcode-block" id="Lexer.go_back"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.go_back">[docs]</a>    <span class="k">def</span> <span class="nf">go_back</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_toks</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This method allows the lexer to go back in time by `num_toks`</span>
<span class="sd">        tokens.  Going back one with `go_back(1)` or just `go_back()` results</span>
<span class="sd">        in the current token being set to a re-scanned version of the previous</span>
<span class="sd">        token.  The text being parsed is restored to the state before those</span>
<span class="sd">        `num_toks` previous tokens were scanned, and the farthest one back is</span>
<span class="sd">        immediately re-scanned.  Lookahead tokens in the buffer are also</span>
<span class="sd">        re-scanned.  This operation is different from the usual pushback</span>
<span class="sd">        operations because the program text is re-scanned, rather than simply</span>
<span class="sd">        backing up to already-scanned tokens.</span>
<span class="sd">        </span>
<span class="sd">        Values of `num_toks` less than one apply to the current token and</span>
<span class="sd">        loohahead tokens.  Calling `go_back(0)` re-scans the current token and</span>
<span class="sd">        all tokens in the lookahead buffer; `go_back(-1)` re-scans only the</span>
<span class="sd">        tokens in the buffer ahead of the current token.  Values greater than</span>
<span class="sd">        one go farther back in the token stream.  Attempts to go back before</span>
<span class="sd">        the beginning of the program text go back to the beginning and stop</span>
<span class="sd">        there.</span>
<span class="sd">        </span>
<span class="sd">        This method returns the current token after any re-scanning.</span>

<span class="sd">        This kind of backup method can be necessary when the token definitions</span>
<span class="sd">        themselves are dynamically changed, such as by a semantic action.  For</span>
<span class="sd">        example, a declaration for the string &quot;my_fun&quot; as a variable might</span>
<span class="sd">        dynamically add a token for that new variable, which would then stop it</span>
<span class="sd">        from matching a general identifier with an on_ties value set to, say,</span>
<span class="sd">        -1.&quot;&quot;&quot;</span>
        <span class="c">#def print_debug(msg=&quot;&quot;):</span>
        <span class="c">#    print(msg, &quot;   token_buffer:&quot;, self.token_buffer, </span>
        <span class="c">#            &quot;\n   previous_tokens:&quot;, self.previous_tokens,</span>
        <span class="c">#            &quot;\n   prog_unprocessed:&quot;, self.prog_unprocessed,</span>
        <span class="c">#            &quot;\n   linenumber, charnumber:&quot;, self.linenumber, self.charnumber)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_generator_state</span> <span class="o">==</span> <span class="n">GenTokenState</span><span class="o">.</span><span class="n">uninitialized</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s">&quot;The token generator has not been initialized &quot;</span>
                  <span class="s">&quot;or has reached StopIteration by reading past the end token.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">MAX_GO_BACK_TOKENS</span> <span class="ow">and</span> <span class="n">num_toks</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">MAX_GO_BACK_TOKENS</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s">&quot;Attempt to go back {0} tokens when MAX_GO_BACK_LEVELS&quot;</span>
                    <span class="s">&quot; is set to {1}.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_toks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">MAX_GO_BACK_TOKENS</span><span class="p">))</span>

        <span class="n">num_non_ends_in_buf</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="bp">True</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span>
                                        <span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">token_label</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_token_label</span><span class="p">])</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">num_toks</span> <span class="o">+</span> <span class="n">num_non_ends_in_buf</span>

        <span class="c"># Pop the tokens from self.previous_tokens, resetting self.prog_unprocessed.</span>
        <span class="n">peek_token_is_first</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="n">current_token_is_first</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="n">n</span><span class="p">:</span> <span class="k">break</span>
            <span class="n">popped</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">previous_tokens</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">popped</span><span class="o">.</span><span class="n">token_label</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">begin_token_label</span><span class="p">:</span>
                <span class="n">peek_token_is_first</span> <span class="o">=</span> <span class="bp">True</span>
                <span class="k">break</span>
            <span class="k">if</span> <span class="n">popped</span><span class="o">.</span><span class="n">token_label</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_token_label</span><span class="p">:</span>
                <span class="n">i</span> <span class="o">-=</span>  <span class="mi">1</span> <span class="c"># End tokens aren&#39;t actually read from the token stream.</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">popped</span><span class="o">.</span><span class="n">ignored_before</span><span class="p">():</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linenumber</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">charnumber</span><span class="p">)</span> <span class="o">=</span> <span class="n">popped</span><span class="o">.</span><span class="n">ignored_before</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">line_and_char</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">linenumber</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">charnumber</span> <span class="o">=</span> <span class="n">popped</span><span class="o">.</span><span class="n">line_and_char</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">non_ignored_token_count</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">all_token_count</span> <span class="o">-=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">popped</span><span class="o">.</span><span class="n">ignored_before</span><span class="p">()))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-=</span> <span class="nb">len</span><span class="p">(</span><span class="n">popped</span><span class="o">.</span><span class="n">original_matched_string</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_begin_token</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">previous_tokens</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">current_token_is_first</span> <span class="o">=</span> <span class="bp">True</span>

        <span class="c"># Re-scan the necessary tokens in the token buffer.</span>
        <span class="k">if</span> <span class="n">peek_token_is_first</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_token_buffer</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="o">-</span><span class="n">num_toks</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">)):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_generator</span><span class="p">()</span>

        <span class="c"># Reset some state variables.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_buffer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">peek_token_is_first</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">peek</span><span class="p">()</span><span class="o">.</span><span class="n">is_first</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_returned_first_token</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_curr_token_is_first</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">elif</span> <span class="n">current_token_is_first</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="o">.</span><span class="n">is_first</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_returned_first_token</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_curr_token_is_first</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_end_token</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">already_returned_end_token</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">already_returned_end_token</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span>

    <span class="c">#</span>
    <span class="c"># Informational methods</span>
    <span class="c">#</span>
</div>
<div class="viewcode-block" id="Lexer.is_begin_token"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.is_begin_token">[docs]</a>    <span class="k">def</span> <span class="nf">is_begin_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Test whether the token is the end token.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">token</span><span class="o">.</span><span class="n">token_label</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">begin_token_label</span>
</div>
<div class="viewcode-block" id="Lexer.curr_token_is_begin"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.curr_token_is_begin">[docs]</a>    <span class="k">def</span> <span class="nf">curr_token_is_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;True if `self.token` (the last one returned by the `next` method) is</span>
<span class="sd">        the begin token.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="o">.</span><span class="n">token_label</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">begin_token_label</span>
</div>
<div class="viewcode-block" id="Lexer.curr_token_is_first"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.curr_token_is_first">[docs]</a>    <span class="k">def</span> <span class="nf">curr_token_is_first</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;True if `self.token` (the last one returned by the `next` function)</span>
<span class="sd">        is the first actual token in the currently-set program text.  Resetting</span>
<span class="sd">        the text resets this.  This value is also set as the attribute</span>
<span class="sd">        `is_first` on all returned tokens.  This is useful, for example, for</span>
<span class="sd">        finding indentation levels (along with `ignored_before_curr`).&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="o">.</span><span class="n">is_first</span>
</div>
<div class="viewcode-block" id="Lexer.ignored_before_curr"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.ignored_before_curr">[docs]</a>    <span class="k">def</span> <span class="nf">ignored_before_curr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the list of all tokens ignored just before `self.token` (the</span>
<span class="sd">        last token returned by the `next` function).  Useful for enforcing</span>
<span class="sd">        things like syntactic whitespace requirements, along with</span>
<span class="sd">        `curr_token_is_first`. This list is also set as the attribute</span>
<span class="sd">        `ignored_before_tokens` on all returned tokens.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="o">.</span><span class="n">ignored_before_tokens</span>
</div>
<div class="viewcode-block" id="Lexer.is_end_token"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.is_end_token">[docs]</a>    <span class="k">def</span> <span class="nf">is_end_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Test whether `token` is the end token.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">token</span><span class="o">.</span><span class="n">token_label</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_token_label</span>
</div>
<div class="viewcode-block" id="Lexer.curr_token_is_end"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.curr_token_is_end">[docs]</a>    <span class="k">def</span> <span class="nf">curr_token_is_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;True if `self.token` (the last one returned by the `next` method) is</span>
<span class="sd">        the end token.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token</span><span class="o">.</span><span class="n">token_label</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_token_label</span>
</div>
<div class="viewcode-block" id="Lexer.is_defined_token_label"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.is_defined_token_label">[docs]</a>    <span class="k">def</span> <span class="nf">is_defined_token_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return true if `token` is currently defined as a token label.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_labels</span>

    <span class="c">#</span>
    <span class="c"># Methods to define and undefine tokens</span>
    <span class="c">#</span>
</div>
<div class="viewcode-block" id="Lexer.define_token"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.define_token">[docs]</a>    <span class="k">def</span> <span class="nf">define_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">,</span> <span class="n">regex_string</span><span class="p">,</span> <span class="n">ignore</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">on_ties</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Define a token and the regex to recognize it.  The label</span>
<span class="sd">        `token_label` is the label for the kind of token.  Setting</span>
<span class="sd">        `ignore=True` will cause all such tokens to be ignored (except that</span>
<span class="sd">        they will be placed on the `ignored_before` list of the non-ignored</span>
<span class="sd">        token that they precede).  In case of ties for the longest match in</span>
<span class="sd">        scanning, the integer `on_ties` values are used to break the ties.  If</span>
<span class="sd">        any two are still equal an exception will be raised.  Returns the new</span>
<span class="sd">        token subclass.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_defined_token_label</span><span class="p">(</span><span class="n">token_label</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s">&quot;Token {0} is already defined.  It must be undefined&quot;</span>
                                 <span class="s">&quot; before it can be redefined.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">token_label</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_insert_pattern</span><span class="p">(</span><span class="n">regex_string</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_label</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">on_ties</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">on_ties</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ignore</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_tokens</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">token_label</span><span class="p">)</span>
        <span class="c"># Initialize with a bare-bones, default token_subclass.</span>
        <span class="n">new_subclass</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">symbol_table</span><span class="o">.</span><span class="n">create_token_subclass</span><span class="p">(</span><span class="n">token_label</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_subclass</span>
</div>
<div class="viewcode-block" id="Lexer.undefine_token"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.undefine_token">[docs]</a>    <span class="k">def</span> <span class="nf">undefine_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Undefine the token corresponding to `token_label`.&quot;&quot;&quot;</span>
        <span class="c"># Remove from the list of defined tokens and the symbol table.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">symbol_table</span><span class="o">.</span><span class="n">undefine_token_subclass</span><span class="p">(</span><span class="n">token_label</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore_tokens</span><span class="o">.</span><span class="n">discard</span><span class="p">(</span><span class="n">token_label</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span> <span class="n">tok_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_labels</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">token_label</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span> <span class="k">return</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_labels</span><span class="p">[</span><span class="n">tok_index</span><span class="p">]</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_regexes</span><span class="p">[</span><span class="n">tok_index</span><span class="p">]</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_ties</span><span class="p">[</span><span class="n">tok_index</span><span class="p">]</span>
</div>
<div class="viewcode-block" id="Lexer.define_begin_and_end_tokens"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.define_begin_and_end_tokens">[docs]</a>    <span class="k">def</span> <span class="nf">define_begin_and_end_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">begin_token_label</span><span class="p">,</span> <span class="n">end_token_label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Define the sentinel tokens at the beginning and end of the token</span>
<span class="sd">        stream.  This method must be called before using the Lexer.  Returns</span>
<span class="sd">        a tuple of the new begin and end token subclasses.  These tokens do not</span>
<span class="sd">        need to be defined with `define_token` because they are never actually</span>
<span class="sd">        scanned in the program text (which would require the regex pattern).&quot;&quot;&quot;</span>
        <span class="c"># begin</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">begin_token_label</span> <span class="o">=</span> <span class="n">begin_token_label</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">begin_token_subclass</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">symbol_table</span><span class="o">.</span><span class="n">create_token_subclass</span><span class="p">(</span>
                                                                <span class="n">begin_token_label</span><span class="p">)</span>
        <span class="c"># end</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_token_label</span> <span class="o">=</span> <span class="n">end_token_label</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_token_subclass</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">symbol_table</span><span class="o">.</span><span class="n">create_token_subclass</span><span class="p">(</span>
                                                                <span class="n">end_token_label</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">begin_token_subclass</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_token_subclass</span>
</div>
<div class="viewcode-block" id="Lexer.define_unstored_token"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.define_unstored_token">[docs]</a>    <span class="k">def</span> <span class="nf">define_unstored_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Define a token that is not stored in the symbol table dict, and which</span>
<span class="sd">        has no regex pattern.&quot;&quot;&quot;</span>
        <span class="n">new_subclass</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">symbol_table</span><span class="o">.</span><span class="n">create_token_subclass</span><span class="p">(</span>
                                                <span class="n">token_label</span><span class="p">,</span> <span class="n">store_in_dict</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_subclass</span>

    <span class="c">#</span>
    <span class="c"># Lower-level methods related to token generation</span>
    <span class="c">#</span>
</div>
    <span class="k">def</span> <span class="nf">_insert_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regex_string</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Insert the pattern in the list of patterns.&quot;&quot;&quot;</span>
        <span class="c"># TODO prepare for using trie for simple patterns</span>
        <span class="c"># Note negative lookbehind assertion (?&lt;!\\) for escape before</span>
        <span class="c"># the strings which start Python regex special chars.</span>
        <span class="c"># TODO move string below up to global space after testing.</span>
        <span class="n">non_simple_regex_contains</span> <span class="o">=</span> \
                <span class="sd">r&quot;&quot;&quot;(</span>
<span class="sd">                        ( (?&lt;!\\)[.^$*+?{[|(] )+ # Start of special char.</span>
<span class="sd">                    |   ( [\\][ABdDsSwWZ] )+     # Python regex escape.</span>
<span class="sd">                    )&quot;&quot;&quot;</span>
        <span class="n">compiled_non_simple_regex_contains</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
                                  <span class="n">non_simple_regex_contains</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">VERBOSE</span><span class="o">|</span><span class="n">re</span><span class="o">.</span><span class="n">UNICODE</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">is_simple_pattern</span><span class="p">(</span><span class="n">regex_string</span><span class="p">):</span>
            <span class="c"># TODO more complicated: could be single-char in brackets!</span>
            <span class="c"># https://docs.python.org/2.0/ref/strings.html</span>
            <span class="n">match_object</span> <span class="o">=</span> <span class="n">compiled_non_simple_regex_contains</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">regex_string</span><span class="p">)</span>
            <span class="c">#matched_string = regex_string[match_object.start():match_object.end()]</span>
            <span class="c">#print(&quot; substring&quot;, matched_string)</span>
            <span class="k">return</span> <span class="ow">not</span> <span class="nb">bool</span><span class="p">(</span><span class="n">match_object</span><span class="p">)</span>

        <span class="c">#if is_simple_pattern(regex_string):</span>
        <span class="c">#    print(&quot;simple pattern&quot;, regex_string)</span>
        <span class="c">#else:</span>
        <span class="c">#    print(&quot;non-simple pattern&quot;, regex_string)</span>

        <span class="c"># below is actual code</span>
        <span class="n">compiled_regex</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">regex_string</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">VERBOSE</span><span class="o">|</span><span class="n">re</span><span class="o">.</span><span class="n">MULTILINE</span><span class="o">|</span><span class="n">re</span><span class="o">.</span><span class="n">UNICODE</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compiled_regexes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">compiled_regex</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_matched_prefixes_and_length_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;A utility routine to do the actual string match on the prefix of</span>
<span class="sd">        `self.program`.  Return the list of matching prefixes and a list of</span>
<span class="sd">        (length, on_ties) data for ranking them.&quot;&quot;&quot;</span>
        <span class="c"># Python&#39;s finditer finds the *first* match group and stops.  They</span>
        <span class="c"># are ordered by the order they occur in the regex.  It finds the</span>
        <span class="c"># longest match of any particular group, but stops when it finds a</span>
        <span class="c"># match of some group.  Instead of that, this code loops over the</span>
        <span class="c"># separate patterns to find the overall longest, breaking ties with</span>
        <span class="c"># on_ties values. </span>
        <span class="n">matching_prefixes_list</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># All the prefix strings that match some token.</span>
        <span class="n">len_and_on_ties_list</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># Ordered like matching_prefixes_list (len, on_ties)</span>
        <span class="k">for</span> <span class="n">count</span><span class="p">,</span> <span class="n">patt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">compiled_regexes</span><span class="p">):</span>
            <span class="n">match_object</span> <span class="o">=</span> <span class="n">patt</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="p">,</span> 
                                      <span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                      <span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">match_object</span><span class="p">:</span> 
                <span class="n">matched_string</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="p">[</span>
                                 <span class="n">match_object</span><span class="o">.</span><span class="n">start</span><span class="p">():</span><span class="n">match_object</span><span class="o">.</span><span class="n">end</span><span class="p">()]</span>
                <span class="n">matching_prefixes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">matched_string</span><span class="p">)</span>
                <span class="c"># Save info to compare matches by length, break ties if necessary.</span>
                <span class="n">len_on_ties_tuple</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">matched_string</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_ties</span><span class="p">[</span><span class="n">count</span><span class="p">])</span>
                <span class="n">len_and_on_ties_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">len_on_ties_tuple</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span> <span class="c"># Match returns None if nothing matches, not a MatchObject.</span>
                <span class="n">matching_prefixes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">)</span>
                <span class="n">len_and_on_ties_list</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">on_ties</span><span class="p">[</span><span class="n">count</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">matching_prefixes_list</span><span class="p">,</span> <span class="n">len_and_on_ties_list</span>

    <span class="k">def</span> <span class="nf">_find_winning_token_label_and_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                                 <span class="n">matching_prefixes_list</span><span class="p">,</span> <span class="n">len_and_on_ties_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Find the `(len, on_ties)` tuple in `len_and_on_ties_list` which is</span>
<span class="sd">        longest and wins tie breaking.  Return the token label and value of the</span>
<span class="sd">        matching prefix.  The list arguments should be in correspondence with</span>
<span class="sd">        the `self.token_labels` list.&quot;&quot;&quot;</span>
        <span class="c"># Note that tuple comparisons give the correct max value.</span>
        <span class="n">winning_tuple</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">len_and_on_ties_list</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">winning_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s">&quot;No matches in Lexer, unknown token at &quot;</span>
                    <span class="s">&quot;the start of this unprocessed text:</span><span class="se">\n</span><span class="s">{0}&quot;</span>
                    <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                            <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ERROR_MSG_TEXT_SNIPPET_SIZE</span><span class="p">]))</span>

        <span class="c"># We know the winning tuple&#39;s value, now see if it is unique.</span>
        <span class="n">winning_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">len_and_on_ties_list</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">len_and_on_ties_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">winning_tuple</span><span class="p">:</span>
                <span class="n">winning_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">winning_indices</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span> <span class="c"># Still have a tie, raise an exception.</span>
            <span class="n">win_labels</span> <span class="o">=</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">winning_indices</span> <span class="p">]</span>
            <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s">&quot;There were multiple token-pattern matches&quot;</span>
                    <span class="s">&quot; with the same length, found in Lexer.  Set the on_ties&quot;</span>
                    <span class="s">&quot; keyword arguments to break ties.  The possible token &quot;</span>
                    <span class="s">&quot; types are: {0}</span><span class="se">\n</span><span class="s">Ambiguity at the start of this &quot;</span>
                    <span class="s">&quot; unprocessed text:</span><span class="se">\n</span><span class="s">{1}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">win_labels</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                            <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ERROR_MSG_TEXT_SNIPPET_SIZE</span><span class="p">]))</span>

        <span class="c"># Got unique winner; use its index to get corresponding winning_index.</span>
        <span class="n">winning_index</span> <span class="o">=</span> <span class="n">winning_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_labels</span><span class="p">[</span><span class="n">winning_index</span><span class="p">]</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">matching_prefixes_list</span><span class="p">[</span><span class="n">winning_index</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">label</span><span class="p">,</span> <span class="n">value</span>

<div class="viewcode-block" id="Lexer.token_generator"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.Lexer.token_generator">[docs]</a>    <span class="k">def</span> <span class="nf">token_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This routine generates tokens from the program text in</span>
<span class="sd">        `self.program`.  It does not modify the program itself, but keeps slice</span>
<span class="sd">        indices in a list `self.prog_unprocessed` indexing the unprocessed</span>
<span class="sd">        part.  That slice can be externally modified (the `go_back` routine</span>
<span class="sd">        does this).</span>
<span class="sd">        </span>
<span class="sd">        This is a lower-level function used by `next` to do the real work.  All</span>
<span class="sd">        the token subclasses should have been defined and stored in the the</span>
<span class="sd">        `TokenSubclassSymbolTable`.  Regexes defined for tokens are repeatedly</span>
<span class="sd">        matched at the beinning of the string `program`.  When a winning_index</span>
<span class="sd">        is found it is stripped off the beginning of the unprocessed slice of</span>
<span class="sd">        `program` and the generator waits for the next call.  For each</span>
<span class="sd">        winning_index the token subclass is looked up in the</span>
<span class="sd">        `TokenSubclassSymbolTable` object and an instance of that subclass is</span>
<span class="sd">        yielded to represent the token.  Every token processed is represented</span>
<span class="sd">        by a unique new instance of the appropriate subclass of `TokenNode`.</span>
<span class="sd">        </span>
<span class="sd">        This generator has two states which can be set class-globally to alter</span>
<span class="sd">        the state of the generator.  The states are `GenTokenState.ordinary`</span>
<span class="sd">        for ordinary scanning execution, and `GenTokenState.end` when all the</span>
<span class="sd">        tokens have been read and the generator keeps returning nothing but end</span>
<span class="sd">        tokens.  The end state is normally entered when the program text</span>
<span class="sd">        becomes empty.  If that variable is later is set to have text again the</span>
<span class="sd">        state switches back to ordinary.&quot;&quot;&quot;</span>
        <span class="n">ignored_before_labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">ignored_before_tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">original_matched_string</span> <span class="o">=</span> <span class="s">&quot;&quot;</span>

        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_curr_token_is_first</span> <span class="o">=</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_returned_first_token</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_returned_first_token</span> <span class="o">=</span> <span class="bp">True</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">token_generator_state</span> <span class="o">=</span> <span class="n">GenTokenState</span><span class="o">.</span><span class="n">end</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">token_generator_state</span> <span class="o">=</span> <span class="n">GenTokenState</span><span class="o">.</span><span class="n">ordinary</span>

            <span class="c"># =======================================================================</span>
            <span class="c"># === Ordinary execution state ==========================================</span>
            <span class="c"># =======================================================================</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_generator_state</span> <span class="o">==</span> <span class="n">GenTokenState</span><span class="o">.</span><span class="n">ordinary</span><span class="p">:</span>
                <span class="c"># Get the matching prefixes and length-ranking information.</span>

                <span class="n">matching_prefixes_list</span><span class="p">,</span> <span class="n">len_and_on_ties_list</span> <span class="o">=</span> \
                                   <span class="bp">self</span><span class="o">.</span><span class="n">_get_matched_prefixes_and_length_info</span><span class="p">()</span>

                <span class="c"># Find the label and value of the matching prefix which is longest</span>
                <span class="c"># (with ties broken by the on_ties values).</span>
                <span class="n">label</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_find_winning_token_label_and_value</span><span class="p">(</span>
                                    <span class="n">matching_prefixes_list</span><span class="p">,</span> <span class="n">len_and_on_ties_list</span><span class="p">)</span>

                <span class="c"># Remove matched prefix of the self.prog_unprocessed argument after</span>
                <span class="c"># saving the matched prefix string.</span>
                <span class="n">original_matched_string</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                                                <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">prog_unprocessed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

                <span class="c"># Look up the class to represent the winning_index.</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">token_subclass_for_label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">symbol_table</span><span class="o">.</span><span class="n">get_token_subclass</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
                <span class="k">except</span> <span class="n">LexerException</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">LexerException</span><span class="p">(</span><span class="s">&quot;Undefined key in symbol table for &quot;</span>
                                         <span class="s">&quot;this label: {0}.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label</span><span class="p">))</span>

                <span class="c"># Make an instance of the class to return (or at least to save</span>
                <span class="c"># in the token&#39;s ignored_before if ignored).</span>
                <span class="n">tci</span> <span class="o">=</span> <span class="n">token_subclass_for_label</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">all_token_count</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c"># Save the line and char counts for the beginning of the token</span>
                <span class="c"># with the token, then update them to the beginning of the next</span>
                <span class="c"># token.  The Lexer class versions always hold the beginning of</span>
                <span class="c"># the next token to be read (into the last buffer slot, not as</span>
                <span class="c"># the current token); the versions stored with the tokens</span>
                <span class="c"># themselves hold the beginning of text when this routine</span>
                <span class="c"># scanned that token (including any ignored text before it).</span>
                <span class="n">tci</span><span class="o">.</span><span class="n">line_and_char</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linenumber</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">charnumber</span><span class="p">)</span>
                <span class="n">num_newlines</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">linenumber</span> <span class="o">+=</span> <span class="n">num_newlines</span>
                <span class="k">if</span> <span class="n">num_newlines</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">charnumber</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">last_newline</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">rfind</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">charnumber</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">original_matched_strings</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">last_newline</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
                
                <span class="c"># ------------------------------------------------------------------</span>
                <span class="c"># Go to the top of the loop and get another if the token is ignored.</span>
                <span class="c"># ------------------------------------------------------------------</span>
                <span class="k">if</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_tokens</span><span class="p">:</span>
                    <span class="n">ignored_before_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
                    <span class="n">ignored_before_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tci</span><span class="p">)</span>
                    <span class="k">continue</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">previous_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tci</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">non_ignored_token_count</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c"># =======================================================================</span>
            <span class="c"># === Return only end tokens state ======================================</span>
            <span class="c"># =======================================================================</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_generator_state</span> <span class="o">==</span> <span class="n">GenTokenState</span><span class="o">.</span><span class="n">end</span><span class="p">:</span>
                <span class="n">token_subclass_for_end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">symbol_table</span><span class="o">.</span><span class="n">get_token_subclass</span><span class="p">(</span>
                                                             <span class="bp">self</span><span class="o">.</span><span class="n">end_token_label</span><span class="p">)</span>
                <span class="n">tci</span> <span class="o">=</span> <span class="n">token_subclass_for_end</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
                <span class="n">tci</span><span class="o">.</span><span class="n">line_and_char</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linenumber</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">charnumber</span><span class="p">)</span>
                <span class="c"># Only save a single end token on previous_tokens list.</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">previous_tokens</span> <span class="ow">and</span> <span class="ow">not</span> 
                                <span class="bp">self</span><span class="o">.</span><span class="n">is_end_token</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">previous_tokens</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">previous_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tci</span><span class="p">)</span>

            <span class="c"># Got a token to return.  Set some attributes and return it.</span>
            <span class="n">tci</span><span class="o">.</span><span class="n">original_matched_string</span> <span class="o">=</span> <span class="n">original_matched_string</span>
            <span class="n">tci</span><span class="o">.</span><span class="n">ignored_before_tokens</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">ignored_before_tokens</span><span class="p">)</span>
            <span class="n">tci</span><span class="o">.</span><span class="n">all_token_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_token_count</span>
            <span class="n">tci</span><span class="o">.</span><span class="n">non_ignored_token_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_ignored_token_count</span>
            <span class="n">tci</span><span class="o">.</span><span class="n">is_first</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_curr_token_is_first</span>

            <span class="k">return</span> <span class="n">tci</span>

<span class="c">#</span>
<span class="c"># Exceptions</span>
<span class="c">#</span>
</div></div>
<div class="viewcode-block" id="LexerException"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.LexerException">[docs]</a><span class="k">class</span> <span class="nc">LexerException</span><span class="p">(</span><span class="ne">Exception</span><span class="p">):</span>
    <span class="k">pass</span>
</div>
<div class="viewcode-block" id="BufferIndexError"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.BufferIndexError">[docs]</a><span class="k">class</span> <span class="nc">BufferIndexError</span><span class="p">(</span><span class="ne">IndexError</span><span class="p">):</span>
    <span class="k">pass</span>

<span class="c">#</span>
<span class="c"># Local testing</span>
<span class="c">#</span>


<span class="c"># TOKEN DEFINITIONS #################################################################</span>
</div>
<div class="viewcode-block" id="define_whitespace_tokens"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.define_whitespace_tokens">[docs]</a><span class="k">def</span> <span class="nf">define_whitespace_tokens</span><span class="p">(</span><span class="n">lex_or_pp</span><span class="p">):</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;space&quot;</span><span class="p">,</span> <span class="s">r&quot;[ \t]+&quot;</span><span class="p">,</span> <span class="n">ignore</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c"># note + NOT *</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;newline&quot;</span><span class="p">,</span> <span class="s">r&quot;[\n\f\r\v]+&quot;</span><span class="p">,</span> <span class="n">ignore</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c"># note + NOT *</span>
    <span class="c">#lex_or_pp.define_token(&quot;whitespace&quot;, r&quot;\s+&quot;, ignore=True) # note + NOT *</span>
</div>
<div class="viewcode-block" id="define_basic_tokens"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.define_basic_tokens">[docs]</a><span class="k">def</span> <span class="nf">define_basic_tokens</span><span class="p">(</span><span class="n">lex_or_pp</span><span class="p">):</span>
    <span class="n">define_whitespace_tokens</span><span class="p">(</span><span class="n">lex_or_pp</span><span class="p">)</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_begin_and_end_tokens</span><span class="p">(</span><span class="s">&quot;begin&quot;</span><span class="p">,</span> <span class="s">&quot;end&quot;</span><span class="p">)</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;number&quot;</span><span class="p">,</span> <span class="s">r&quot;\d+&quot;</span><span class="p">)</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;imag_number&quot;</span><span class="p">,</span> <span class="s">r&quot;\d+[i]&quot;</span><span class="p">)</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;double_ast&quot;</span><span class="p">,</span> <span class="s">r&quot;(?:\*\*|\^)&quot;</span><span class="p">)</span> <span class="c"># Note ^ is defined as synonym.</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;plus&quot;</span><span class="p">,</span> <span class="s">r&quot;\+&quot;</span><span class="p">)</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;minus&quot;</span><span class="p">,</span> <span class="s">r&quot;\-&quot;</span><span class="p">)</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;fslash&quot;</span><span class="p">,</span> <span class="s">r&quot;/&quot;</span><span class="p">)</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;ast&quot;</span><span class="p">,</span> <span class="s">r&quot;\*&quot;</span><span class="p">)</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;lpar&quot;</span><span class="p">,</span> <span class="s">r&quot;\(&quot;</span><span class="p">)</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;rpar&quot;</span><span class="p">,</span> <span class="s">r&quot;\)&quot;</span><span class="p">)</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;comma&quot;</span><span class="p">,</span> <span class="s">r&quot;,&quot;</span><span class="p">)</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;bang&quot;</span><span class="p">,</span> <span class="s">r&quot;!&quot;</span><span class="p">)</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;question&quot;</span><span class="p">,</span> <span class="s">r&quot;\?&quot;</span><span class="p">)</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;colon&quot;</span><span class="p">,</span> <span class="s">r&quot;\:&quot;</span><span class="p">)</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;semicolon&quot;</span><span class="p">,</span> <span class="s">r&quot;;&quot;</span><span class="p">)</span>
</div>
<div class="viewcode-block" id="define_identifier_token"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.define_identifier_token">[docs]</a><span class="k">def</span> <span class="nf">define_identifier_token</span><span class="p">(</span><span class="n">lex_or_pp</span><span class="p">):</span>
    <span class="c"># The last part of below only needs \w, but good example of pattern.</span>
    <span class="c">#lex_or_pp.define_token(&quot;identifier&quot;, r&quot;[a-zA-Z_](?:[\w|\d]*)&quot;, on_ties=-1)</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;identifier&quot;</span><span class="p">,</span> <span class="s">r&quot;[a-zA-Z_](?:\w*)&quot;</span><span class="p">,</span> <span class="n">on_ties</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</div>
<div class="viewcode-block" id="define_default_tokens"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.define_default_tokens">[docs]</a><span class="k">def</span> <span class="nf">define_default_tokens</span><span class="p">(</span><span class="n">lex_or_pp</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Defines some default tokens for testing either a Lexer or a PrattParser.&quot;&quot;&quot;</span>
    <span class="n">define_basic_tokens</span><span class="p">(</span><span class="n">lex_or_pp</span><span class="p">)</span>
    <span class="n">define_identifier_token</span><span class="p">(</span><span class="n">lex_or_pp</span><span class="p">)</span>
</div>
<div class="viewcode-block" id="define_comment_to_EOL_token"><a class="viewcode-back" href="../../wff_language.lexer.html#wff_language.lexer.define_comment_to_EOL_token">[docs]</a><span class="k">def</span> <span class="nf">define_comment_to_EOL_token</span><span class="p">(</span><span class="n">lex_or_pp</span><span class="p">,</span> <span class="n">begin_string</span><span class="p">):</span>
    <span class="c"># Note that comment_to_endline is non-greedy due to *? symbol.</span>
    <span class="n">lex_or_pp</span><span class="o">.</span><span class="n">define_token</span><span class="p">(</span><span class="s">&quot;comment_to_EOL&quot;</span><span class="p">,</span> <span class="s">r&quot;{0}.*?[\n]&quot;</span>
                           <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">begin_string</span><span class="p">),</span> <span class="n">ignore</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

</div>
<span class="kn">import</span> <span class="nn">pytest_helper</span>
<span class="n">pytest_helper</span><span class="o">.</span><span class="n">script_run</span><span class="p">(</span><span class="s">&quot;test/test_lexer.py&quot;</span><span class="p">,</span> <span class="n">pytest_args</span><span class="o">=</span><span class="s">&quot;-v&quot;</span><span class="p">)</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">Skolem  documentation</a> &raquo;</li>
          <li><a href="../index.html" >Module code</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2015, Allen Barker.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
    </div>
  </body>
</html>